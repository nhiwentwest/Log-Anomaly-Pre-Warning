{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# HDFS V2 TRUE Pre-Warning (Time-based + Drain3)\n",
                "\n",
                "Like BGL: timestamp-based labeling with DELTA_SEC"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, json, random, re\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")\n",
                "\n",
                "# ===== KAGGLE PATHS (FIXED) =====\n",
                "BASE = \"/kaggle/working\"\n",
                "CKPT_DIR = \"/kaggle/input/hdfs-ew3\"\n",
                "V2_PATH = \"/kaggle/input/loghub-hdfs-hadoop-distributed-file-system-data/HDFS_v2/node_logs\"\n",
                "DRAIN_TEMPLATES = None  # Will parse fresh with Drain3\n",
                "OUTPUT_DIR = f\"{BASE}/output-hdfsv2ew3\"\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "print(f\"V2_PATH contents: {os.listdir(V2_PATH)[:5]}...\")\n",
                "\n",
                "CONTEXT_LEN, D_MODEL, N_HEADS, N_LAYERS = 128, 256, 8, 4\n",
                "PAD, CLS, MASK, SEP, OFF = 0, 1, 2, 3, 4\n",
                "BATCH_SIZE, SEED = 64, 42\n",
                "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
                "\n",
                "DELTA_MIN = 5\n",
                "DELTA_SEC = DELTA_MIN * 60\n",
                "SESSION_GAP = 3600"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ===== LOAD PARSED DATA (FROM LOCAL CPU) =====\n",
                "import pickle\n",
                "\n",
                "# Kaggle path\n",
                "PKL_FILE = \"/kaggle/input/hdfsv2-parsed/hdfsv2_parsed_data.pkl\"\n",
                "\n",
                "with open(PKL_FILE, 'rb') as f:\n",
                "    data = pickle.load(f)\n",
                "\n",
                "v2_events_raw = data['v2_events_raw']\n",
                "normal_traces = data['normal_traces']\n",
                "failure_traces = data['failure_traces']\n",
                "train_normal = data['train_normal']\n",
                "test_normal = data['test_normal']\n",
                "train_failure = data['train_failure']\n",
                "test_failure = data['test_failure']\n",
                "train_windows = data['train_windows']\n",
                "NUM_TEMPLATES = data['NUM_TEMPLATES']\n",
                "VOCAB_SIZE = data['VOCAB_SIZE']\n",
                "OLD_VOCAB_SIZE = data['OLD_VOCAB_SIZE']\n",
                "\n",
                "print(f\"Loaded parsed data!\")\n",
                "print(f\"Events: {len(v2_events_raw):,}\")\n",
                "print(f\"VOCAB_SIZE: {VOCAB_SIZE}\")\n",
                "print(f\"Train windows: {len(train_windows):,}\")\n",
                "print(f\"Test: {len(test_normal)} N, {len(test_failure)} F\")\n",
                "print(\"\\n>>> SKIP parsing cells, go to DATASET & MODEL <<<\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LOAD CHECKPOINT (skip drain templates - parse fresh)\n",
                "ckpt = torch.load(f\"{CKPT_DIR}/checkpoints_logbert_ep11.pt\", map_location=device)\n",
                "VOCAB_SIZE = ckpt['model_state_dict']['tok.weight'].shape[0]\n",
                "print(f\"VOCAB: {VOCAB_SIZE}\")\n",
                "\n",
                "template_map = {}  # Empty - will parse fresh\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PARSE V2 RAW LOGS WITH DRAIN3 (REUSE OLD TEMPLATE MAPPING)\n",
                "print(\"PARSING V2 LOGS\")\n",
                "!pip install drain3 -q\n",
                "from drain3 import TemplateMiner\n",
                "from drain3.template_miner_config import TemplateMinerConfig\n",
                "from datetime import datetime\n",
                "\n",
                "# Initialize Drain3\n",
                "config = TemplateMinerConfig()\n",
                "config.drain_depth = 4\n",
                "config.drain_sim_th = 0.4\n",
                "miner = TemplateMiner(config=config)\n",
                "\n",
                "# Anomaly patterns\n",
                "ANOMALY_PATTERNS = ['ERROR', 'Exception', 'failed', 'timeout', 'IOException']\n",
                "import re\n",
                "anomaly_regex = re.compile('|'.join(ANOMALY_PATTERNS), re.IGNORECASE)\n",
                "\n",
                "def parse_timestamp(line):\n",
                "    m = re.search(r'(?P<y>\\d{4})-(?P<m>\\d{2})-(?P<d>\\d{2})[ T]'\n",
                "                  r'(?P<h>\\d{2}):(?P<mi>\\d{2}):(?P<s>\\d{2})(?:[,\\.](?P<ms>\\d{3}))?',\n",
                "                  line)\n",
                "    if m:\n",
                "        y = int(m.group('y')); mo = int(m.group('m')); d = int(m.group('d'))\n",
                "        h = int(m.group('h')); mi = int(m.group('mi')); s = int(m.group('s'))\n",
                "        return int(datetime(y, mo, d, h, mi, s).timestamp())\n",
                "    m2 = re.search(r'(?P<d>\\d{6})\\s+(?P<t>\\d{6})', line)\n",
                "    if m2:\n",
                "        d = m2.group('d'); t = m2.group('t')\n",
                "        day = int(d[4:6]); h = int(t[:2]); mi = int(t[2:4]); s = int(t[4:6])\n",
                "        return day*86400 + h*3600 + mi*60 + s\n",
                "    return None\n",
                "\n",
                "# Track unknown templates\n",
                "next_unknown_id = VOCAB_SIZE\n",
                "unknown_templates = {}\n",
                "\n",
                "def get_tid(line):\n",
                "    global next_unknown_id\n",
                "    result = miner.add_log_message(line)\n",
                "    cluster = result if hasattr(result, 'get_template') else result.get('cluster')\n",
                "    if cluster is None:\n",
                "        return VOCAB_SIZE - 1  # Unknown fallback\n",
                "    template_str = cluster.get_template() if hasattr(cluster, 'get_template') else str(cluster)\n",
                "    # Try to map to old template\n",
                "    if template_str in template_map:\n",
                "        return template_map[template_str]\n",
                "    # New template - assign new ID (track but keep in vocab range)\n",
                "    if template_str not in unknown_templates:\n",
                "        unknown_templates[template_str] = len(unknown_templates)\n",
                "    return min(VOCAB_SIZE - 1, VOCAB_SIZE - 10 + unknown_templates[template_str])\n",
                "\n",
                "# Parse all log files\n",
                "v2_events_raw = []\n",
                "log_files = [f for f in os.listdir(V2_PATH) if f.endswith('.log')]\n",
                "print(f\"Parsing {len(log_files)} log files...\")\n",
                "\n",
                "for file_id, log_file in enumerate(tqdm(log_files)):\n",
                "    filepath = os.path.join(V2_PATH, log_file)\n",
                "    with open(filepath, 'r', errors='ignore') as f:\n",
                "        for line in f:\n",
                "            line = line.strip()\n",
                "            if not line: continue\n",
                "            ts = parse_timestamp(line)\n",
                "            if ts is None: continue\n",
                "            is_anomaly = bool(anomaly_regex.search(line))\n",
                "            tid = get_tid(line)\n",
                "            v2_events_raw.append((ts, tid, is_anomaly, file_id))\n",
                "\n",
                "NUM_TEMPLATES = len(miner.drain.clusters)\n",
                "print(f\"Total events (with timestamp): {len(v2_events_raw):,}\")\n",
                "print(f\"Templates found: {NUM_TEMPLATES}\")\n",
                "print(f\"Mapped to old vocab: {NUM_TEMPLATES - len(unknown_templates)}\")\n",
                "print(f\"New unknown templates: {len(unknown_templates)}\")\n",
                "print(f\"Anomalies: {sum(1 for _,_,a,_ in v2_events_raw if a):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SAVE PARSED DATA (Ch\u1ea1y sau khi parse xong) ===\n",
                "import pickle\n",
                "parsed_data = {\n",
                "    'events': v2_events_raw,\n",
                "    'num_templates': NUM_TEMPLATES,\n",
                "    'unknown_templates': unknown_templates\n",
                "}\n",
                "with open(f\"{OUTPUT_DIR}/v2_parsed.pkl\", 'wb') as f:\n",
                "    pickle.dump(parsed_data, f)\n",
                "print(f\"\u2705 Saved parsed data: {len(v2_events_raw):,} events\")\n",
                "\n",
                "# Clear raw events to save memory\n",
                "# del v2_events_raw; import gc; gc.collect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CREATE TRACES (per-file, sorted by timestamp)\n",
                "print(\"\\nCREATING TRACES\")\n",
                "from collections import defaultdict\n",
                "\n",
                "# Group by file, then sort by timestamp within file\n",
                "file_events = defaultdict(list)\n",
                "for ts, tid, anom, file_id in v2_events_raw:\n",
                "    file_events[file_id].append((ts, tid, anom))\n",
                "\n",
                "# Create sessions within each file\n",
                "sessions = []\n",
                "for file_id, events in file_events.items():\n",
                "    events.sort(key=lambda x: x[0])  # Sort by timestamp\n",
                "    current, last_time = [], None\n",
                "    for ts, tid, anom in events:\n",
                "        if last_time and ts - last_time > SESSION_GAP:\n",
                "            if current: sessions.append(current)\n",
                "            current = []\n",
                "        current.append((ts, tid, anom))\n",
                "        last_time = ts\n",
                "    if current: sessions.append(current)\n",
                "\n",
                "print(f\"Total sessions: {len(sessions)}\")\n",
                "\n",
                "# Filter to traces\n",
                "normal_traces, failure_traces = [], []\n",
                "for sess in sessions:\n",
                "    tids = [tid for _,tid,_ in sess]\n",
                "    if len(tids) >= 20:\n",
                "        if any(a for _,_,a in sess):\n",
                "            failure_traces.append({'tids': tids, 'events': sess})\n",
                "        else:\n",
                "            normal_traces.append({'tids': tids, 'events': sess})\n",
                "\n",
                "print(f\"Normal: {len(normal_traces)}, Failure: {len(failure_traces)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CREATE WINDOWS (time-based like BGL)\n",
                "WINDOW_SIZE, STEP_SIZE = 256, 64\n",
                "\n",
                "def create_windows(traces, is_failure=False):\n",
                "    windows = []\n",
                "    for trace in traces:\n",
                "        tids, events = trace['tids'], trace.get('events')\n",
                "        n = len(tids)\n",
                "        for i in range(0, max(1, n - WINDOW_SIZE + 1), STEP_SIZE):\n",
                "            end = min(i + WINDOW_SIZE, n)\n",
                "            w_tids = tids[i:end]\n",
                "            if is_failure and events:\n",
                "                end_time = events[min(end-1, n-1)][0]\n",
                "                has_future = False\n",
                "                if end_time:\n",
                "                    for j in range(end, n):\n",
                "                        if events[j][0] and events[j][0] > end_time + DELTA_SEC: break\n",
                "                        if events[j][2]: has_future = True; break\n",
                "                has_current = any(events[k][2] for k in range(i, min(end, n)))\n",
                "                label = 1 if (has_current or has_future) else 0\n",
                "            else:\n",
                "                label = 0\n",
                "            windows.append({'tids': w_tids, 'label': label})\n",
                "    return windows\n",
                "\n",
                "def create_prewarn_windows(traces):\n",
                "    windows = []\n",
                "    for trace in traces:\n",
                "        tids, events = trace['tids'], trace.get('events')\n",
                "        n = len(tids)\n",
                "        for i in range(0, max(1, n - WINDOW_SIZE + 1), STEP_SIZE):\n",
                "            end = min(i + WINDOW_SIZE, n)\n",
                "            has_current = any(events[k][2] for k in range(i, min(end, n)))\n",
                "            if has_current: continue  # TRUE pre-warning only\n",
                "            end_time = events[min(end-1, n-1)][0]\n",
                "            has_future = False\n",
                "            if end_time:\n",
                "                for j in range(end, n):\n",
                "                    if events[j][0] and events[j][0] > end_time + DELTA_SEC: break\n",
                "                    if events[j][2]: has_future = True; break\n",
                "            label = 1 if has_future else 0\n",
                "            windows.append({'tids': tids[i:end], 'label': label})\n",
                "    return windows\n",
                "\n",
                "# Safe split\n",
                "def safe_split(n, ratio=0.8):\n",
                "    return n-1 if n>1 and int(n*ratio)==n else max(1, int(n*ratio))\n",
                "\n",
                "rng = np.random.RandomState(SEED)\n",
                "n_idx = rng.permutation(len(normal_traces)) if normal_traces else []\n",
                "f_idx = rng.permutation(len(failure_traces)) if failure_traces else []\n",
                "n_split = safe_split(len(normal_traces)) if normal_traces else 0\n",
                "f_split = safe_split(len(failure_traces)) if failure_traces else 0\n",
                "\n",
                "train_normal = [normal_traces[i] for i in n_idx[:n_split]] if normal_traces else []\n",
                "test_normal = [normal_traces[i] for i in n_idx[n_split:]] if normal_traces else []\n",
                "train_failure = [failure_traces[i] for i in f_idx[:f_split]] if failure_traces else []\n",
                "test_failure = [failure_traces[i] for i in f_idx[f_split:]] if failure_traces else []\n",
                "\n",
                "print(f\"Train: {len(train_normal)} N, {len(train_failure)} F\")\n",
                "print(f\"Test: {len(test_normal)} N, {len(test_failure)} F\")\n",
                "\n",
                "# Stage 1 windows\n",
                "s1_windows = create_windows(train_normal) + create_windows(train_failure, True)\n",
                "s1_pos = sum(1 for w in s1_windows if w['label']==1)\n",
                "print(f\"Stage 1: {len(s1_windows):,} windows (pos={s1_pos:,})\")\n",
                "\n",
                "# Stage 2 windows (TRUE pre-warning)\n",
                "s2_windows = create_windows(train_normal) + create_prewarn_windows(train_failure)\n",
                "s2_pos = sum(1 for w in s2_windows if w['label']==1)\n",
                "print(f\"Stage 2: {len(s2_windows):,} windows (pos={s2_pos:,})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SAVE TRACES + WINDOWS (Ch\u1ea1y sau khi t\u1ea1o windows xong) ===\n",
                "import pickle\n",
                "processed_data = {\n",
                "    'train_normal': train_normal,\n",
                "    'train_failure': train_failure,\n",
                "    'test_normal': test_normal,\n",
                "    'test_failure': test_failure,\n",
                "    's1_windows': s1_windows,\n",
                "    's2_windows': s2_windows,\n",
                "    's1_pos': s1_pos,\n",
                "    's2_pos': s2_pos\n",
                "}\n",
                "with open(f\"{OUTPUT_DIR}/v2_processed.pkl\", 'wb') as f:\n",
                "    pickle.dump(processed_data, f)\n",
                "print(f\"\u2705 Saved processed data: {len(s1_windows):,} S1, {len(s2_windows):,} S2 windows\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === LOAD SAVED DATA (Thay cho parse n\u1ebfu \u0111\u00e3 c\u00f3) ===\n",
                "# Uncomment \u0111\u1ec3 load thay v\u00ec parse:\n",
                "\n",
                "# import pickle\n",
                "# with open(f\"{OUTPUT_DIR}/v2_processed.pkl\", 'rb') as f:\n",
                "#     data = pickle.load(f)\n",
                "# train_normal = data['train_normal']\n",
                "# train_failure = data['train_failure']\n",
                "# test_normal = data['test_normal']\n",
                "# test_failure = data['test_failure']\n",
                "# s1_windows = data['s1_windows']\n",
                "# s2_windows = data['s2_windows']\n",
                "# s1_pos = data['s1_pos']\n",
                "# s2_pos = data['s2_pos']\n",
                "# print(f\"\u2705 Loaded: {len(s1_windows):,} S1, {len(s2_windows):,} S2 windows\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DATASET + MODEL (same as BGL)\n",
                "class BalancedDataset(Dataset):\n",
                "    def __init__(self, windows, vs, ratio=5):\n",
                "        self.pos = [w for w in windows if w['label']==1]\n",
                "        self.neg = [w for w in windows if w['label']==0]\n",
                "        self.vs, self.ratio = vs, ratio\n",
                "        self.n = len(self.pos)*(1+ratio) if self.pos else len(self.neg)\n",
                "    def __len__(self): return self.n\n",
                "    def __getitem__(self, idx):\n",
                "        w = random.choice(self.pos) if (self.pos and idx%(self.ratio+1)==0) else random.choice(self.neg if self.neg else self.pos)\n",
                "        s = [min(t+OFF, self.vs-1) for t in w['tids'][:CONTEXT_LEN-2]]\n",
                "        tok = [CLS]+s+[SEP]+[PAD]*(CONTEXT_LEN-len(s)-2)\n",
                "        masked, mlm = tok.copy(), [-100]*len(tok)\n",
                "        if s:\n",
                "            for p in np.random.choice(len(s), min(max(1,int(len(s)*0.15)),len(s)), replace=False)+1:\n",
                "                mlm[p] = masked[p]; masked[p] = MASK\n",
                "        return {'ids': torch.tensor(masked), 'mask': torch.tensor([1 if t!=PAD else 0 for t in masked]),\n",
                "                'ew': torch.tensor(w['label'], dtype=torch.float), 'mlm': torch.tensor(mlm)}\n",
                "\n",
                "class LogBERTEW(nn.Module):\n",
                "    def __init__(self, vs):\n",
                "        super().__init__()\n",
                "        self.tok = nn.Embedding(vs, D_MODEL, padding_idx=PAD)\n",
                "        self.pos = nn.Embedding(CONTEXT_LEN, D_MODEL)\n",
                "        self.drop = nn.Dropout(0.1)\n",
                "        self.enc = nn.TransformerEncoder(nn.TransformerEncoderLayer(D_MODEL, N_HEADS, D_MODEL*4, 0.1, 'gelu', batch_first=True), N_LAYERS)\n",
                "        self.head = nn.Linear(D_MODEL, vs)\n",
                "        self.ew_head = nn.Linear(D_MODEL, 1)\n",
                "        self.register_buffer('ctr', torch.zeros(D_MODEL)); self.ci = False\n",
                "    def forward(self, ids, mask=None):\n",
                "        x = self.tok(ids) + self.pos(torch.arange(ids.size(1), device=ids.device))\n",
                "        h = self.enc(self.drop(x), src_key_padding_mask=(mask==0) if mask is not None else None)\n",
                "        return self.head(h), h[:,0,:], self.ew_head(h[:,0,:]).squeeze(-1)\n",
                "    def upd(self, e):\n",
                "        with torch.no_grad(): bc = e.mean(0); self.ctr = bc if not self.ci else 0.9*self.ctr+0.1*bc; self.ci = True\n",
                "\n",
                "model = LogBERTEW(VOCAB_SIZE).to(device)\n",
                "model.load_state_dict(ckpt['model_state_dict'], strict=False)\n",
                "model.ctr = ckpt['center'].to(device); model.ci = True\n",
                "print(f\"Model loaded: VOCAB={VOCAB_SIZE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# STAGE 1 TRAINING\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"STAGE 1: Detection + Pre-warning\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "LAMBDA_MLM, LAMBDA_VHM, MU_EW = 0.4, 0.1, 1.0\n",
                "s1_ds = BalancedDataset(s1_windows, VOCAB_SIZE)\n",
                "s1_loader = DataLoader(s1_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
                "POS_WEIGHT = (len(s1_windows)-s1_pos) / max(s1_pos, 1)\n",
                "ew_crit = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([POS_WEIGHT], device=device))\n",
                "scaler = torch.amp.GradScaler('cuda') if device.type=='cuda' else None\n",
                "best = float('inf')\n",
                "\n",
                "# Phase 1\n",
                "print(\"Phase 1\")\n",
                "for p in model.parameters(): p.requires_grad = False\n",
                "for p in model.ew_head.parameters(): p.requires_grad = True\n",
                "opt = torch.optim.Adam(model.ew_head.parameters(), lr=1e-4)\n",
                "for ep in range(2):\n",
                "    model.train(); tl = 0\n",
                "    for b in tqdm(s1_loader, desc=f\"P1.{ep+1}\"):\n",
                "        opt.zero_grad(); _, _, ew = model(b['ids'].to(device), b['mask'].to(device))\n",
                "        loss = ew_crit(ew, b['ew'].to(device)); loss.backward(); opt.step(); tl += loss.item()\n",
                "    print(f\"  {ep+1}: {tl/len(s1_loader):.4f}\")\n",
                "\n",
                "# Phase 2\n",
                "print(\"Phase 2\")\n",
                "for p in model.parameters(): p.requires_grad = True\n",
                "opt = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
                "for ep in range(8):\n",
                "    model.train(); tl = 0\n",
                "    for b in tqdm(s1_loader, desc=f\"P2.{ep+1}\"):\n",
                "        ids, mask, ew_l, mlm_l = b['ids'].to(device), b['mask'].to(device), b['ew'].to(device), b['mlm'].to(device)\n",
                "        opt.zero_grad()\n",
                "        if scaler:\n",
                "            with torch.amp.autocast('cuda'):\n",
                "                mlm_lg, cls, ew = model(ids, mask)\n",
                "                loss = LAMBDA_MLM*F.cross_entropy(mlm_lg.view(-1,VOCAB_SIZE), mlm_l.view(-1), ignore_index=-100) + LAMBDA_VHM*torch.mean((cls-model.ctr)**2) + MU_EW*ew_crit(ew, ew_l)\n",
                "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
                "        else:\n",
                "            mlm_lg, cls, ew = model(ids, mask)\n",
                "            loss = LAMBDA_MLM*F.cross_entropy(mlm_lg.view(-1,VOCAB_SIZE), mlm_l.view(-1), ignore_index=-100) + LAMBDA_VHM*torch.mean((cls-model.ctr)**2) + MU_EW*ew_crit(ew, ew_l)\n",
                "            loss.backward(); opt.step()\n",
                "        model.upd(cls.detach()); tl += loss.item()\n",
                "    avg = tl/len(s1_loader); print(f\"  {ep+1}: {avg:.4f}\")\n",
                "    if avg < best: best = avg; torch.save(model.state_dict(), f\"{OUTPUT_DIR}/hdfsv2_ew_stage1.pt\")\n",
                "\n",
                "print(f\"Stage 1 best: {best:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# STAGE 2: TRUE PRE-WARNING\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"STAGE 2: TRUE Pre-Warning\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "model.load_state_dict(torch.load(f\"{OUTPUT_DIR}/hdfsv2_ew_stage1.pt\", map_location=device))\n",
                "print(\"Loaded Stage 1 checkpoint\")\n",
                "\n",
                "s2_ds = BalancedDataset(s2_windows, VOCAB_SIZE)\n",
                "s2_loader = DataLoader(s2_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
                "POS_WEIGHT_S2 = (len(s2_windows)-s2_pos) / max(s2_pos, 1)\n",
                "ew_crit_s2 = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([POS_WEIGHT_S2], device=device))\n",
                "\n",
                "opt = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
                "best_s2 = float('inf')\n",
                "\n",
                "for ep in range(5):\n",
                "    model.train(); tl = 0\n",
                "    for b in tqdm(s2_loader, desc=f\"S2.{ep+1}\"):\n",
                "        ids, mask, ew_l, mlm_l = b['ids'].to(device), b['mask'].to(device), b['ew'].to(device), b['mlm'].to(device)\n",
                "        opt.zero_grad()\n",
                "        if scaler:\n",
                "            with torch.amp.autocast('cuda'):\n",
                "                mlm_lg, cls, ew = model(ids, mask)\n",
                "                loss = 0.2*F.cross_entropy(mlm_lg.view(-1,VOCAB_SIZE), mlm_l.view(-1), ignore_index=-100) + 0.1*torch.mean((cls-model.ctr)**2) + 1.0*ew_crit_s2(ew, ew_l)\n",
                "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
                "        else:\n",
                "            mlm_lg, cls, ew = model(ids, mask)\n",
                "            loss = 0.2*F.cross_entropy(mlm_lg.view(-1,VOCAB_SIZE), mlm_l.view(-1), ignore_index=-100) + 0.1*torch.mean((cls-model.ctr)**2) + 1.0*ew_crit_s2(ew, ew_l)\n",
                "            loss.backward(); opt.step()\n",
                "        model.upd(cls.detach()); tl += loss.item()\n",
                "    avg = tl/len(s2_loader); print(f\"  {ep+1}: {avg:.4f}\")\n",
                "    if avg < best_s2: best_s2 = avg; torch.save(model.state_dict(), f\"{OUTPUT_DIR}/hdfsv2_ew_prewarn.pt\")\n",
                "\n",
                "print(f\"Stage 2 best: {best_s2:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# EVALUATION\n",
                "print(\"\\nEVALUATION\")\n",
                "model.load_state_dict(torch.load(f\"{OUTPUT_DIR}/hdfsv2_ew_prewarn.pt\", map_location=device))\n",
                "model.eval()\n",
                "\n",
                "@torch.no_grad()\n",
                "def score_trace(tids, step=32):\n",
                "    probs = []\n",
                "    for k in range(min(WINDOW_SIZE, len(tids)), len(tids)+1, step):\n",
                "        s = [min(t+OFF, VOCAB_SIZE-1) for t in tids[max(0,k-WINDOW_SIZE):k]]\n",
                "        if len(s) < 10: continue\n",
                "        tok = [CLS]+s[:CONTEXT_LEN-2]+[SEP]+[PAD]*(CONTEXT_LEN-len(s[:CONTEXT_LEN-2])-2)\n",
                "        ids = torch.tensor([tok], device=device)\n",
                "        _, _, ew = model(ids)\n",
                "        probs.append((k, torch.sigmoid(ew).item()))\n",
                "    return probs\n",
                "\n",
                "failure_scores = [{'trace': t, 'max_prob': max(p for _,p in score_trace(t['tids'])), 'probs': score_trace(t['tids'])} \n",
                "                  for t in tqdm(test_failure) if score_trace(t['tids'])]\n",
                "normal_scores = [{'trace': t, 'max_prob': max(p for _,p in score_trace(t['tids']))} \n",
                "                 for t in tqdm(test_normal) if score_trace(t['tids'])]\n",
                "print(f\"Scored: {len(failure_scores)} F, {len(normal_scores)} N\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# F1-OPTIMAL + METRICS\n",
                "all_probs = [s['max_prob'] for s in failure_scores] + [s['max_prob'] for s in normal_scores]\n",
                "all_labels = [1]*len(failure_scores) + [0]*len(normal_scores)\n",
                "\n",
                "auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else 0.5\n",
                "prec, rec, thr = precision_recall_curve(all_labels, all_probs)\n",
                "f1 = 2*prec*rec/(prec+rec+1e-9)\n",
                "best_idx = f1.argmax()\n",
                "TH = thr[best_idx] if best_idx < len(thr) else thr[-1] if len(thr) > 0 else 0.5\n",
                "\n",
                "tp, leads = [], []\n",
                "for s in failure_scores:\n",
                "    if s['max_prob'] > TH:\n",
                "        tp.append(s)\n",
                "        for k, p in s['probs']:\n",
                "            if p > TH: # FIXED: calculate lead to first anomaly\n; break\n",
                "fp = [s for s in normal_scores if s['max_prob'] > TH]\n",
                "\n",
                "recall = len(tp)/len(failure_scores) if failure_scores else 0\n",
                "far = len(fp)/len(normal_scores) if normal_scores else 0\n",
                "precision = len(tp)/(len(tp)+len(fp)) if (len(tp)+len(fp))>0 else 0\n",
                "f1_final = 2*precision*recall/(precision+recall) if (precision+recall)>0 else 0\n",
                "\n",
                "print(f\"\\n=== RESULTS ===\")\n",
                "print(f\"AUC: {auc:.4f}, TH: {TH:.4f}\")\n",
                "print(f\"F1: {f1_final:.4f}, P: {precision:.4f}, R: {recall:.4f}, FAR: {far:.4f}\")\n",
                "if leads: print(f\"Lead: median={np.median(leads):.0f}, mean={np.mean(leads):.0f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SAVE\n",
                "results = {'dataset': 'HDFS_V2', 'method': 'curriculum_true_prewarn_timebased',\n",
                "    'metrics': {'auc': float(auc), 'threshold': float(TH), 'f1': float(f1_final),\n",
                "        'precision': float(precision), 'recall': float(recall), 'far': float(far),\n",
                "        'lead_median': float(np.median(leads)) if leads else 0,\n",
                "        'lead_mean': float(np.mean(leads)) if leads else 0}}\n",
                "with open(f\"{OUTPUT_DIR}/hdfsv2_ew_results.json\", 'w') as f: json.dump(results, f, indent=2)\n",
                "print(f\"Saved: {OUTPUT_DIR}/hdfsv2_ew_results.json\")\n",
                "print(json.dumps(results['metrics'], indent=2))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Post-Training Analysis: validation-calibrated thresholds, lead-to-first-anomaly, FAR\u2013Recall, PR/ROC, CIs\n",
                "import math, statistics\n",
                "from sklearn.metrics import auc, confusion_matrix\n",
                "\n",
                "# 1) Helpers --------------------------------------------------------------\n",
                "\n",
                "def first_anomaly_index(trace):\n",
                "    events = trace.get('events') or []\n",
                "    for i, (_, _, is_anom) in enumerate(events):\n",
                "        if is_anom:\n",
                "            return i\n",
                "    return None  # normal\n",
                "\n",
                "@torch.no_grad()\n",
                "def trace_scores_pre_anom(trace, step=32):\n",
                "    \"\"\"Return (max_prob_pre, probs list, first_anom_idx).\n",
                "    probs: list[(k, p)] as produced by score_trace, but computed here once for reuse.\n",
                "    max_prob_pre considers only prefixes strictly before the first anomaly index.\n",
                "    For normal traces (first_idx=None), considers all prefixes.\n",
                "    \"\"\"\n",
                "    tids = trace['tids']\n",
                "    probs = score_trace(tids, step=step)\n",
                "    q = first_anomaly_index(trace)\n",
                "    if q is None:\n",
                "        max_pre = max((p for _, p in probs), default=0.0)\n",
                "    else:\n",
                "        max_pre = max((p for k, p in probs if (k - 1) < q), default=0.0)\n",
                "    return max_pre, probs, q\n",
                "\n",
                "\n",
                "def earliest_crossing_k(probs, threshold, first_idx):\n",
                "    \"\"\"Earliest prefix length k where p>threshold and (k-1) < first_idx (if exists).\"\"\"\n",
                "    for k, p in probs:\n",
                "        if p > threshold and (first_idx is None or (k - 1) < first_idx):\n",
                "            return k\n",
                "    return None\n",
                "\n",
                "\n",
                "def lead_events_from_crossing(k_cross, first_idx):\n",
                "    \"\"\"Lead (in events) to first anomaly = max(0, q - k + 1).\"\"\"\n",
                "    if k_cross is None or first_idx is None:\n",
                "        return None\n",
                "    return max(0, first_idx - k_cross + 1)\n",
                "\n",
                "\n",
                "def split_validation_test(norm_list, fail_list, val_ratio=0.3, seed=SEED):\n",
                "    rng = np.random.RandomState(seed)\n",
                "    nN, nF = len(norm_list), len(fail_list)\n",
                "    nN_val = int(max(1, round(nN * val_ratio))) if nN > 0 else 0\n",
                "    nF_val = int(max(1, round(nF * val_ratio))) if nF > 0 else 0\n",
                "    n_idx = rng.permutation(nN) if nN > 0 else np.array([], dtype=int)\n",
                "    f_idx = rng.permutation(nF) if nF > 0 else np.array([], dtype=int)\n",
                "    val_norm = [norm_list[i] for i in n_idx[:nN_val]]\n",
                "    tst_norm = [norm_list[i] for i in n_idx[nN_val:]]\n",
                "    val_fail = [fail_list[i] for i in f_idx[:nF_val]]\n",
                "    tst_fail = [fail_list[i] for i in f_idx[nF_val:]]\n",
                "    return val_norm, val_fail, tst_norm, tst_fail\n",
                "\n",
                "\n",
                "# 2) Build validation/test splits (from held-out traces) ------------------\n",
                "val_normal, val_failure, final_normal, final_failure = split_validation_test(\n",
                "    test_normal, test_failure, val_ratio=0.3, seed=SEED)\n",
                "print(f\"Validation: {len(val_normal)} N, {len(val_failure)} F | Test: {len(final_normal)} N, {len(final_failure)} F\")\n",
                "\n",
                "# Score per-trace max pre-anomaly prob for VAL\n",
                "val_norm_scores = [trace_scores_pre_anom(t)[0] for t in tqdm(val_normal, desc=\"VAL normal scores\")]\n",
                "val_fail_scores = [trace_scores_pre_anom(t)[0] for t in tqdm(val_failure, desc=\"VAL failure scores\")]\n",
                "\n",
                "# Score per-trace max pre-anomaly prob and cache probs for TEST\n",
                "final_norm_sc = []\n",
                "final_fail_sc = []\n",
                "final_fail_meta = []  # store (probs, first_idx)\n",
                "for t in tqdm(final_normal, desc=\"TEST normal scores\"):\n",
                "    s, _, _ = trace_scores_pre_anom(t)\n",
                "    final_norm_sc.append(s)\n",
                "for t in tqdm(final_failure, desc=\"TEST failure scores\"):\n",
                "    s, pr, q = trace_scores_pre_anom(t)\n",
                "    final_fail_sc.append(s)\n",
                "    final_fail_meta.append((pr, q))\n",
                "\n",
                "# 3) Threshold calibration on validation by FAR target --------------------\n",
                "far_targets = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1]\n",
                "\n",
                "def threshold_for_far(norm_scores, far):\n",
                "    if len(norm_scores) == 0:\n",
                "        return 1.0\n",
                "    q = max(0.0, min(1.0, 1.0 - far))\n",
                "    return float(np.quantile(norm_scores, q))\n",
                "\n",
                "calib = {float(ft): threshold_for_far(val_norm_scores, ft) for ft in far_targets}\n",
                "print(\"Calibrated thresholds (VAL):\", {k: round(v, 4) for k, v in calib.items()})\n",
                "\n",
                "# 4) Evaluate on TEST at each FAR target ----------------------------------\n",
                "\n",
                "def evaluate_at_threshold(th):\n",
                "    # Per-trace decisions\n",
                "    tp = 0\n",
                "    fp = 0\n",
                "    leads = []\n",
                "    for (probs, q) in final_fail_meta:\n",
                "        kx = earliest_crossing_k(probs, th, q)\n",
                "        if kx is not None:\n",
                "            tp += 1\n",
                "            ld = lead_events_from_crossing(kx, q)\n",
                "            if ld is not None:\n",
                "                leads.append(ld)\n",
                "    for s in final_norm_sc:\n",
                "        if s > th:\n",
                "            fp += 1\n",
                "    nF = len(final_fail_meta) or 1\n",
                "    nN = len(final_norm_sc) or 1\n",
                "    recall = tp / nF\n",
                "    far = fp / nN\n",
                "    precision = tp / max(tp + fp, 1)\n",
                "    f1 = 2 * precision * recall / max(precision + recall, 1e-9)\n",
                "    lead_stats = {\n",
                "        'median': float(np.median(leads)) if leads else 0.0,\n",
                "        'mean': float(np.mean(leads)) if leads else 0.0,\n",
                "        'p25': float(np.percentile(leads, 25)) if leads else 0.0,\n",
                "        'p75': float(np.percentile(leads, 75)) if leads else 0.0,\n",
                "        'count': len(leads)\n",
                "    }\n",
                "    return {'f1': float(f1), 'precision': float(precision), 'recall': float(recall),\n",
                "            'far': float(far), 'lead': lead_stats,\n",
                "            'tp': int(tp), 'fp': int(fp), 'nF': int(nF), 'nN': int(nN)}\n",
                "\n",
                "far_curve = []\n",
                "for ft in far_targets:\n",
                "    th = calib[float(ft)]\n",
                "    m = evaluate_at_threshold(th)\n",
                "    far_curve.append({'far_target': float(ft), 'threshold': th, **m})\n",
                "\n",
                "# Choose operating point FAR=1% if available\n",
                "op_target = 0.01 if 0.01 in far_targets else far_targets[min(2, len(far_targets)-1)]\n",
                "op_th = calib[float(op_target)]\n",
                "op_metrics = evaluate_at_threshold(op_th)\n",
                "\n",
                "# 5) PR/ROC on TEST using per-trace max pre-anomaly prob -------------------\n",
                "all_scores = np.array(final_fail_sc + final_norm_sc, dtype=float)\n",
                "all_labels = np.array([1]*len(final_fail_sc) + [0]*len(final_norm_sc), dtype=int)\n",
                "roc = float(roc_auc_score(all_labels, all_scores)) if len(set(all_labels))>1 else 0.5\n",
                "pr_p, pr_r, _ = precision_recall_curve(all_labels, all_scores)\n",
                "pr = float(auc(pr_r, pr_p)) if len(pr_r)>1 else 0.0\n",
                "\n",
                "# 6) Bootstrap 95% CI at operating point ----------------------------------\n",
                "\n",
                "def bootstrap_ci(n_boot=300, seed=SEED):\n",
                "    rng = np.random.RandomState(seed)\n",
                "    f_idx = np.arange(len(final_fail_meta))\n",
                "    n_idx = np.arange(len(final_norm_sc))\n",
                "    f1s, recs, fars = [], [], []\n",
                "    for _ in range(n_boot):\n",
                "        bf = rng.choice(f_idx, size=len(f_idx), replace=True) if len(f_idx)>0 else []\n",
                "        bn = rng.choice(n_idx, size=len(n_idx), replace=True) if len(n_idx)>0 else []\n",
                "        tp = 0; fp = 0\n",
                "        for i in bf:\n",
                "            probs, q = final_fail_meta[i]\n",
                "            if earliest_crossing_k(probs, op_th, q) is not None:\n",
                "                tp += 1\n",
                "        for j in bn:\n",
                "            if final_norm_sc[j] > op_th:\n",
                "                fp += 1\n",
                "        nF = max(1, len(f_idx)); nN = max(1, len(n_idx))\n",
                "        recall = tp / nF\n",
                "        far = fp / nN\n",
                "        precision = tp / max(tp + fp, 1)\n",
                "        f1 = 2*precision*recall / max(precision+recall, 1e-9)\n",
                "        f1s.append(f1); recs.append(recall); fars.append(far)\n",
                "    def ci(arr):\n",
                "        if not arr: return [0.0, 0.0]\n",
                "        lo, hi = np.percentile(arr, [2.5, 97.5])\n",
                "        return [float(lo), float(hi)]\n",
                "    return {'f1': ci(f1s), 'recall': ci(recs), 'far': ci(fars)}\n",
                "\n",
                "cis = bootstrap_ci()\n",
                "\n",
                "# 7) Save consolidated JSON -----------------------------------------------\n",
                "report = {\n",
                "    'dataset': 'HDFS_V2',\n",
                "    'method': 'true_prewarn_analysis',\n",
                "    'config': {\n",
                "        'delta_min': int(DELTA_MIN),\n",
                "        'window_size': int(WINDOW_SIZE),\n",
                "        'step_size': 32,\n",
                "        'far_targets': far_targets\n",
                "    },\n",
                "    'validation': {\n",
                "        'n_normal': len(val_normal), 'n_failure': len(val_failure),\n",
                "        'thresholds_by_far': {str(k): float(v) for k, v in calib.items()}\n",
                "    },\n",
                "    'test': {\n",
                "        'n_normal': len(final_normal), 'n_failure': len(final_failure),\n",
                "        'operating_point': {'far_target': float(op_target), 'threshold': float(op_th)},\n",
                "        'metrics': {\n",
                "            'roc_auc': roc,\n",
                "            'pr_auc': pr,\n",
                "            **op_metrics\n",
                "        },\n",
                "        'ci_95': cis\n",
                "    },\n",
                "    'far_recall_curve': far_curve,\n",
                "    'notes': 'Threshold calibrated on validation normals by per-trace FAR; lead measured to FIRST anomaly event.'\n",
                "}\n",
                "\n",
                "with open(os.path.join(OUTPUT_DIR, 'hdfsv2_ew_analysis.json'), 'w') as f:\n",
                "    json.dump(report, f, indent=2)\n",
                "print(f\"\\n\u2713 Saved analysis to {OUTPUT_DIR}/hdfsv2_ew_analysis.json\")\n",
                "print(json.dumps(report['test']['metrics'], indent=2))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}