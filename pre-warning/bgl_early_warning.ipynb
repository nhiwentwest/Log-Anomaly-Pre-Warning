{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# BGL Early Warning (Paper-style + Phase 3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, json, random\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
                "\n",
                "!pip install drain3 -q\n",
                "from drain3 import TemplateMiner\n",
                "from drain3.template_miner_config import TemplateMinerConfig\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")\n",
                "\n",
                "# ===== KAGGLE PATHS =====\n",
                "BASE = \"/kaggle/working\"\n",
                "BGL_FILE = \"/kaggle/input/loghub-bgl-log-data/BGL.log\"\n",
                "CKPT_DIR = \"/kaggle/input/bgltest\"\n",
                "EW_OUTPUT = f\"{BASE}/output-bglew3\"\n",
                "os.makedirs(EW_OUTPUT, exist_ok=True)\n",
                "\n",
                "CONTEXT_LEN, D_MODEL, N_HEADS, N_LAYERS = 128, 256, 8, 4\n",
                "PAD, CLS, MASK, SEP = 0, 1, 2, 3\n",
                "BATCH_SIZE, SEED = 64, 42\n",
                "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
                "\n",
                "DELTA_MIN = 5\n",
                "DELTA_SEC = DELTA_MIN * 60\n",
                "WINDOW_SIZE, STEP_SIZE = 128, 8\n",
                "SAMPLING_RATIO = 5"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CREATE WINDOWS (True pre-warning on viable subset)\n# Traces are already windows from sliding window sessionization\n# Label = 1 if alert coming; Label = 0 if normal or too close to alert\n\nDELTA_EVENTS = 50  # Alert within next 50 events = pre-warning positive\n\ndef create_prewarn_data(traces):\n    \"\"\"Create pre-warning training data from viable traces\"\"\"\n    windows = []\n    for t in traces:\n        first_alert = t['first_alert']\n        # Only use prefix BEFORE first_alert\n        # Label = 1 if we're within DELTA_EVENTS of alert\n        for end in range(STRIDE, first_alert, STRIDE):  # Sliding within viable prefix\n            prefix_tids = t['tids'][:end]\n            distance_to_alert = first_alert - end\n            label = 1 if distance_to_alert <= DELTA_EVENTS else 0\n            windows.append({\n                'tids': prefix_tids,\n                'label': label,\n                'distance': distance_to_alert\n            })\n    return windows\n\ndef create_normal_windows(traces, max_per_trace=3):\n    \"\"\"Normal windows (label=0)\"\"\"\n    windows = []\n    for t in traces:\n        for end in range(STRIDE, min(WINDOW, len(t['tids'])), STRIDE)[:max_per_trace]:\n            windows.append({\n                'tids': t['tids'][:end],\n                'label': 0\n            })\n    return windows\n\n# Split train/test\nrng = np.random.RandomState(SEED)\nn_idx = rng.permutation(len(normal_traces))\nf_idx = rng.permutation(len(failure_traces))\nn_split = int(0.7 * len(normal_traces))\nf_split = int(0.7 * len(failure_traces))\n\ntrain_normal = [normal_traces[i] for i in n_idx[:n_split]]\nval_normal = [normal_traces[i] for i in n_idx[n_split:int(0.85*len(normal_traces))]]\ntest_normal = [normal_traces[i] for i in n_idx[int(0.85*len(normal_traces)):]]\n\ntrain_failure = [failure_traces[i] for i in f_idx[:f_split]]\nval_failure = [failure_traces[i] for i in f_idx[f_split:int(0.85*len(failure_traces))]]\ntest_failure = [failure_traces[i] for i in f_idx[int(0.85*len(failure_traces)):]]\n\nprint(f\"Train: {len(train_normal)} N, {len(train_failure)} F\")\nprint(f\"Val: {len(val_normal)} N, {len(val_failure)} F\")\nprint(f\"Test: {len(test_normal)} N, {len(test_failure)} F\")\n\n# Create training windows\ntrain_prewarn = create_prewarn_data(train_failure)\ntrain_norm = create_normal_windows(train_normal)\ntrain_windows = train_norm + train_prewarn\n\nn_pos = sum(1 for w in train_windows if w['label']==1)\nprint(f\"\\nTraining windows: {len(train_windows):,} (pre-warning pos={n_pos:,})\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LOAD CHECKPOINT\n",
                "ckpt = torch.load(f\"{CKPT_DIR}/checkpoints_logbert_ep11.pt\", map_location=device)\n",
                "OLD_VOCAB_SIZE = ckpt['model_state_dict']['tok.weight'].shape[0]\n",
                "print(f\"HDFS VOCAB: {OLD_VOCAB_SIZE}\")\n",
                "\n",
                "config = TemplateMinerConfig()\n",
                "config.drain_depth = 4\n",
                "config.drain_sim_th = 0.4\n",
                "miner = TemplateMiner(config=config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PARSE BGL\n",
                "print(\"PARSING BGL\")\n",
                "\n",
                "def get_cluster_id(result):\n",
                "    return result.get('cluster_id', 0) if isinstance(result, dict) else result.cluster_id\n",
                "\n",
                "bgl_events = []\n",
                "with open(BGL_FILE, 'r', errors='ignore') as f:\n",
                "    for line in tqdm(f, desc=\"BGL\"):\n",
                "        line = line.strip()\n",
                "        if not line: continue\n",
                "        parts = line.split(None, 9)\n",
                "        if len(parts) < 2: continue\n",
                "        is_anomaly = parts[0] != '-'\n",
                "        try: timestamp = int(parts[1])\n",
                "        except: timestamp = None\n",
                "        message = parts[-1]\n",
                "        tid = OLD_VOCAB_SIZE + get_cluster_id(miner.add_log_message(message))\n",
                "        bgl_events.append((timestamp, tid, is_anomaly))\n",
                "\n",
                "NUM_CLUSTERS = len(miner.drain.clusters)\n",
                "VOCAB_SIZE = OLD_VOCAB_SIZE + NUM_CLUSTERS + 10\n",
                "print(f\"Events: {len(bgl_events):,}, BGL Clusters: {NUM_CLUSTERS}, Total VOCAB: {VOCAB_SIZE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CREATE TRACES (Sliding window, viable pre-warning only)\nprint(\"\\nCREATING TRACES (Window=100, Stride=20, viable only)\")\nWINDOW, STRIDE = 100, 20\n\n# Create all sliding windows\nall_windows = []\nn = len(bgl_events)\nfor i in range(0, n - WINDOW + 1, STRIDE):\n    window_events = bgl_events[i:i+WINDOW]\n    tids = [e[1] for e in window_events]\n    first_alert = next((j for j, e in enumerate(window_events) if e[2]), WINDOW)\n    all_windows.append({\n        'tids': tids,\n        'events': window_events,\n        'first_alert': first_alert,\n        'has_alert': first_alert < WINDOW\n    })\n\n# Separate normal vs failure\nnormal_traces = [w for w in all_windows if not w['has_alert']]\nfailure_traces_all = [w for w in all_windows if w['has_alert']]\n\n# Viable pre-warning: alert at position >= STRIDE\nfailure_traces = [w for w in failure_traces_all if w['first_alert'] >= STRIDE]\n\nprint(f\"Total windows: {len(all_windows):,}\")\nprint(f\"Normal: {len(normal_traces):,}\")\nprint(f\"Failure (all): {len(failure_traces_all):,}\")\nprint(f\"Failure (viable pre-warning, alert >= {STRIDE}): {len(failure_traces):,}\")\nprint(f\"\")\nprint(f\">>> Theoretical max recall: {100*len(failure_traces)/len(failure_traces_all):.1f}%\")\nprint(f\">>> Training on viable subset only\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CREATE WINDOWS (Viable Pre-Warning Subset)\nWINDOW_SIZE, STEP_SIZE = 128, 8\nMIN_TIME_TO_ANOM = 60  # Only traces with >60s before first anomaly\n\ndef filter_viable_traces(traces, min_time=MIN_TIME_TO_ANOM):\n    \"\"\"Keep only traces where we have >min_time seconds before first anomaly\"\"\"\n    viable = []\n    for t in traces:\n        events = t.get('events', [])\n        if not events: continue\n        first_ts = events[0][0]\n        first_anom_idx = next((j for j, e in enumerate(events) if e[2]), len(events))\n        if first_anom_idx >= len(events): continue  # No anomaly\n        first_anom_ts = events[first_anom_idx][0]\n        time_to_anom = first_anom_ts - first_ts if first_ts and first_anom_ts else 0\n        if time_to_anom > min_time:\n            viable.append(t)\n    return viable\n\ndef create_prewarn_windows(traces):\n    \"\"\"Create windows BEFORE first anomaly only (true pre-warning)\"\"\"\n    windows = []\n    for trace in traces:\n        tids, events = trace['tids'], trace.get('events')\n        if not events: continue\n        n = len(tids)\n        first_anom_idx = next((j for j, e in enumerate(events) if e[2]), n)\n        \n        # Only create windows BEFORE first anomaly\n        for i in range(0, min(first_anom_idx - WINDOW_SIZE, n - WINDOW_SIZE + 1), STEP_SIZE):\n            end = min(i + WINDOW_SIZE, n)\n            if end <= first_anom_idx:  # Window ends before anomaly\n                # Positive if anomaly coming within DELTA_SEC\n                end_time = events[min(end-1, n-1)][0]\n                first_anom_ts = events[first_anom_idx][0]\n                time_to_anom = first_anom_ts - end_time if end_time and first_anom_ts else float('inf')\n                label = 1 if time_to_anom <= DELTA_SEC else 0\n                windows.append({'tids': tids[i:end], 'label': label, 'time_to_anom': time_to_anom})\n    return windows\n\ndef create_normal_windows(traces):\n    \"\"\"Normal windows (label=0)\"\"\"\n    windows = []\n    for trace in traces:\n        tids = trace['tids']\n        n = len(tids)\n        for i in range(0, max(1, n - WINDOW_SIZE + 1), STEP_SIZE * 4):  # Subsample\n            end = min(i + WINDOW_SIZE, n)\n            windows.append({'tids': tids[i:end], 'label': 0})\n    return windows\n\n# Filter to viable traces\nrng = np.random.RandomState(SEED)\nn_idx, f_idx = rng.permutation(len(normal_traces)), rng.permutation(len(failure_traces))\nn_split, f_split = int(0.8*len(normal_traces)), int(0.8*len(failure_traces))\ntrain_normal = [normal_traces[i] for i in n_idx[:n_split]]\ntest_normal = [normal_traces[i] for i in n_idx[n_split:]]\ntrain_failure_all = [failure_traces[i] for i in f_idx[:f_split]]\ntest_failure_all = [failure_traces[i] for i in f_idx[f_split:]]\n\n# Filter viable\ntrain_failure = filter_viable_traces(train_failure_all)\ntest_failure = filter_viable_traces(test_failure_all)\nprint(f\"Viable: train={len(train_failure)}/{len(train_failure_all)}, test={len(test_failure)}/{len(test_failure_all)}\")\n\n# Create pre-warning windows\ntrain_prewarn = create_prewarn_windows(train_failure)\ntrain_norm_windows = create_normal_windows(train_normal)\ntrain_windows = train_norm_windows + train_prewarn\n\nn_pos = sum(1 for w in train_windows if w['label']==1)\nprint(f\"Train windows: {len(train_windows):,} (prewarn_pos={n_pos:,})\")\nprint(f\"Test: {len(test_normal)} N, {len(test_failure)} F (viable)\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SAVE PARSED DATA (for re-evaluation without re-parsing)\n",
                "import pickle\n",
                "save_data = {\n",
                "    'bgl_events': bgl_events,\n",
                "    'normal_traces': normal_traces,\n",
                "    'failure_traces': failure_traces,\n",
                "    'NUM_CLUSTERS': NUM_CLUSTERS,\n",
                "    'VOCAB_SIZE': VOCAB_SIZE,\n",
                "    'OLD_VOCAB_SIZE': OLD_VOCAB_SIZE,\n",
                "    'train_normal': train_normal,\n",
                "    'test_normal': test_normal,\n",
                "    'train_failure': train_failure,\n",
                "    'test_failure': test_failure\n",
                "}\n",
                "with open(f\"{EW_OUTPUT}/bgl_parsed_data.pkl\", 'wb') as f:\n",
                "    pickle.dump(save_data, f)\n",
                "print(f\"Saved: {EW_OUTPUT}/bgl_parsed_data.pkl\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DATASET & MODEL\n",
                "class BalancedDataset(Dataset):\n",
                "    def __init__(self, windows, vs, ratio=SAMPLING_RATIO):\n",
                "        self.pos = [w for w in windows if w['label']==1]\n",
                "        self.neg = [w for w in windows if w['label']==0]\n",
                "        self.vs, self.ratio = vs, ratio\n",
                "        self.n = len(self.pos)*(1+ratio) if self.pos else len(self.neg)\n",
                "    def __len__(self): return self.n\n",
                "    def __getitem__(self, idx):\n",
                "        w = random.choice(self.pos) if (self.pos and idx%(self.ratio+1)==0) else random.choice(self.neg if self.neg else self.pos)\n",
                "        s = [min(t, self.vs-1) for t in w['tids'][:CONTEXT_LEN-2]]\n",
                "        tok = [CLS]+s+[SEP]+[PAD]*(CONTEXT_LEN-len(s)-2)\n",
                "        masked, mlm_l = tok.copy(), [-100]*len(tok)\n",
                "        if len(s)>0:\n",
                "            for p in np.random.choice(len(s), min(max(1,int(len(s)*0.15)), len(s)), replace=False)+1:\n",
                "                mlm_l[p] = masked[p]; masked[p] = MASK\n",
                "        return {'ids': torch.tensor(masked), 'mask': torch.tensor([1 if t!=PAD else 0 for t in masked]),\n",
                "                'ew_label': torch.tensor(w['label'], dtype=torch.float), 'mlm_labels': torch.tensor(mlm_l)}\n",
                "\n",
                "class LogBERTEW(nn.Module):\n",
                "    def __init__(self, vs):\n",
                "        super().__init__()\n",
                "        self.tok = nn.Embedding(vs, D_MODEL, padding_idx=PAD)\n",
                "        self.pos = nn.Embedding(CONTEXT_LEN, D_MODEL)\n",
                "        self.drop = nn.Dropout(0.1)\n",
                "        self.enc = nn.TransformerEncoder(nn.TransformerEncoderLayer(D_MODEL, N_HEADS, D_MODEL*4, 0.1, 'gelu', batch_first=True), N_LAYERS)\n",
                "        self.head = nn.Linear(D_MODEL, vs)\n",
                "        self.ew_head = nn.Linear(D_MODEL, 1)\n",
                "        self.register_buffer('ctr', torch.zeros(D_MODEL)); self.ci = False\n",
                "    def forward(self, ids, mask=None):\n",
                "        x = self.tok(ids) + self.pos(torch.arange(ids.size(1), device=ids.device))\n",
                "        h = self.enc(self.drop(x), src_key_padding_mask=(mask==0) if mask is not None else None)\n",
                "        return self.head(h), h[:,0,:], self.ew_head(h[:,0,:]).squeeze(-1)\n",
                "    def upd(self, e):\n",
                "        with torch.no_grad(): bc = e.mean(0); self.ctr = bc if not self.ci else 0.9*self.ctr+0.1*bc; self.ci = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# MODEL INIT\n",
                "model = LogBERTEW(VOCAB_SIZE).to(device)\n",
                "with torch.no_grad():\n",
                "    model.tok.weight[:OLD_VOCAB_SIZE] = ckpt['model_state_dict']['tok.weight']\n",
                "    nn.init.normal_(model.tok.weight[OLD_VOCAB_SIZE:], std=0.02)\n",
                "state = {k:v for k,v in ckpt['model_state_dict'].items() if 'tok.weight' not in k and 'head.' not in k}\n",
                "model.load_state_dict(state, strict=False)\n",
                "with torch.no_grad():\n",
                "    model.head.weight[:OLD_VOCAB_SIZE] = ckpt['model_state_dict']['head.weight']\n",
                "    model.head.bias[:OLD_VOCAB_SIZE] = ckpt['model_state_dict']['head.bias']\n",
                "model.ctr = ckpt['center'].to(device); model.ci = True\n",
                "print(f\"Model loaded: {OLD_VOCAB_SIZE} -> {VOCAB_SIZE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TRAINING\n",
                "LAMBDA_MLM, LAMBDA_VHM, MU_EW = 0.4, 0.1, 1.0\n",
                "train_pos = sum(1 for w in train_windows if w['label']==1)\n",
                "POS_WEIGHT = (len(train_windows)-train_pos) / max(train_pos, 1)\n",
                "train_ds = BalancedDataset(train_windows, VOCAB_SIZE)\n",
                "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
                "ew_crit = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([POS_WEIGHT], device=device))\n",
                "scaler = torch.amp.GradScaler('cuda') if device.type=='cuda' else None\n",
                "best = float('inf')\n",
                "\n",
                "# Phase 1\n",
                "print(\"PHASE 1\")\n",
                "for p in model.parameters(): p.requires_grad = False\n",
                "for p in model.ew_head.parameters(): p.requires_grad = True\n",
                "opt = torch.optim.Adam(model.ew_head.parameters(), lr=1e-4)\n",
                "for ep in range(2):\n",
                "    model.train(); tl = 0\n",
                "    for b in tqdm(train_loader, desc=f\"P1.{ep+1}\"):\n",
                "        opt.zero_grad(); _, _, ew = model(b['ids'].to(device), b['mask'].to(device))\n",
                "        loss = ew_crit(ew, b['ew_label'].to(device)); loss.backward(); opt.step(); tl += loss.item()\n",
                "    print(f\"  {ep+1}: {tl/len(train_loader):.4f}\")\n",
                "\n",
                "# Phase 2\n",
                "print(\"\\nPHASE 2\")\n",
                "for p in model.parameters(): p.requires_grad = True\n",
                "opt = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
                "for ep in range(8):\n",
                "    model.train(); tl = 0\n",
                "    for b in tqdm(train_loader, desc=f\"P2.{ep+1}\"):\n",
                "        ids, mask, ew_l, mlm_l = b['ids'].to(device), b['mask'].to(device), b['ew_label'].to(device), b['mlm_labels'].to(device)\n",
                "        opt.zero_grad()\n",
                "        if scaler:\n",
                "            with torch.amp.autocast('cuda'):\n",
                "                mlm_lg, cls, ew = model(ids, mask)\n",
                "                loss = LAMBDA_MLM*F.cross_entropy(mlm_lg.view(-1,VOCAB_SIZE), mlm_l.view(-1), ignore_index=-100) + LAMBDA_VHM*torch.mean((cls-model.ctr)**2) + MU_EW*ew_crit(ew, ew_l)\n",
                "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
                "        else:\n",
                "            mlm_lg, cls, ew = model(ids, mask)\n",
                "            loss = LAMBDA_MLM*F.cross_entropy(mlm_lg.view(-1,VOCAB_SIZE), mlm_l.view(-1), ignore_index=-100) + LAMBDA_VHM*torch.mean((cls-model.ctr)**2) + MU_EW*ew_crit(ew, ew_l)\n",
                "            loss.backward(); opt.step()\n",
                "        model.upd(cls.detach()); tl += loss.item()\n",
                "    avg = tl/len(train_loader); print(f\"  {ep+1}: {avg:.4f}\")\n",
                "    if avg < best: best = avg; torch.save(model.state_dict(), f\"{EW_OUTPUT}/bgl_ew_best.pt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PHASE 3: Fine-tune LR=1e-5 + early stop\n",
                "print(\"\\nPHASE 3 (LR=1e-5 + early-stop)\")\n",
                "opt = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
                "patience, no_improve = 2, 0\n",
                "\n",
                "for ep in range(8):\n",
                "    model.train(); tl = 0\n",
                "    for b in tqdm(train_loader, desc=f\"P3.{ep+1}\"):\n",
                "        ids, mask, ew_l, mlm_l = b['ids'].to(device), b['mask'].to(device), b['ew_label'].to(device), b['mlm_labels'].to(device)\n",
                "        opt.zero_grad()\n",
                "        if scaler:\n",
                "            with torch.amp.autocast('cuda'):\n",
                "                mlm_lg, cls, ew = model(ids, mask)\n",
                "                loss = LAMBDA_MLM*F.cross_entropy(mlm_lg.view(-1,VOCAB_SIZE), mlm_l.view(-1), ignore_index=-100) + LAMBDA_VHM*torch.mean((cls-model.ctr)**2) + MU_EW*ew_crit(ew, ew_l)\n",
                "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
                "        else:\n",
                "            mlm_lg, cls, ew = model(ids, mask)\n",
                "            loss = LAMBDA_MLM*F.cross_entropy(mlm_lg.view(-1,VOCAB_SIZE), mlm_l.view(-1), ignore_index=-100) + LAMBDA_VHM*torch.mean((cls-model.ctr)**2) + MU_EW*ew_crit(ew, ew_l)\n",
                "            loss.backward(); opt.step()\n",
                "        model.upd(cls.detach()); tl += loss.item()\n",
                "    avg = tl/len(train_loader); print(f\"  {ep+1}: {avg:.4f}\")\n",
                "    if avg < best:\n",
                "        best = avg; torch.save(model.state_dict(), f\"{EW_OUTPUT}/bgl_ew_best.pt\"); no_improve = 0\n",
                "    else:\n",
                "        no_improve += 1\n",
                "        if no_improve >= patience: print(f\"  Early stop\"); break\n",
                "print(f\"Best loss: {best:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# STAGE 2: TRUE PRE-WARNING (Clean windows only)\n",
                "print(\"\n",
                "\" + \"=\"*60)\n",
                "print(\"STAGE 2: TRUE Pre-Warning (clean windows only)\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "def create_prewarn_windows(traces):\n",
                "    \"\"\"Windows WITHOUT anomaly inside, but WITH anomaly coming in DELTA_SEC\"\"\"\n",
                "    windows = []\n",
                "    for trace in traces:\n",
                "        tids, events = trace['tids'], trace.get('events')\n",
                "        if not events: continue\n",
                "        n = len(tids)\n",
                "        for i in range(0, max(1, n - WINDOW_SIZE + 1), STEP_SIZE):\n",
                "            end = min(i + WINDOW_SIZE, n)\n",
                "            has_current = any(events[k][2] for k in range(i, min(end, n)))\n",
                "            if has_current: continue\n",
                "            end_time = events[min(end-1, n-1)][0]\n",
                "            has_future = False\n",
                "            if end_time:\n",
                "                for j in range(end, n):\n",
                "                    if events[j][0] and events[j][0] > end_time + DELTA_SEC: break\n",
                "                    if events[j][2]: has_future = True; break\n",
                "            if has_future:\n",
                "                windows.append({'tids': tids[i:end], 'label': 1})\n",
                "    return windows\n",
                "\n",
                "prewarn_windows = create_prewarn_windows(train_failure)\n",
                "s2_normal = create_windows(train_normal, is_failure=False)\n",
                "print(f\"Stage 2: {len(prewarn_windows)} pre-warning + {len(s2_normal)} normal\")\n",
                "\n",
                "if len(prewarn_windows) > 0:\n",
                "    model.load_state_dict(torch.load(f\"{EW_OUTPUT}/bgl_ew_best.pt\", map_location=device))\n",
                "    s2_windows = s2_normal + prewarn_windows\n",
                "    s2_pos = sum(1 for w in s2_windows if w['label']==1)\n",
                "    POS_WEIGHT_S2 = (len(s2_windows)-s2_pos) / max(s2_pos, 1)\n",
                "    s2_ds = BalancedDataset(s2_windows, VOCAB_SIZE, ratio=3)\n",
                "    s2_loader = DataLoader(s2_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
                "    ew_crit_s2 = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([POS_WEIGHT_S2], device=device))\n",
                "    opt = torch.optim.AdamW(model.parameters(), lr=5e-6)\n",
                "    best_s2 = float('inf')\n",
                "    for ep in range(10):\n",
                "        model.train(); tl = 0\n",
                "        for b in tqdm(s2_loader, desc=f\"S2.{ep+1}\"):\n",
                "            ids, mask, ew_l, mlm_l = b['ids'].to(device), b['mask'].to(device), b['ew_label'].to(device), b['mlm_labels'].to(device)\n",
                "            opt.zero_grad()\n",
                "            if scaler:\n",
                "                with torch.amp.autocast('cuda'):\n",
                "                    mlm_lg, cls, ew = model(ids, mask)\n",
                "                    loss = 0.2*F.cross_entropy(mlm_lg.view(-1,VOCAB_SIZE), mlm_l.view(-1), ignore_index=-100) + 0.1*torch.mean((cls-model.ctr)**2) + 1.0*ew_crit_s2(ew, ew_l)\n",
                "                scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
                "            else:\n",
                "                mlm_lg, cls, ew = model(ids, mask)\n",
                "                loss = 0.2*F.cross_entropy(mlm_lg.view(-1,VOCAB_SIZE), mlm_l.view(-1), ignore_index=-100) + 0.1*torch.mean((cls-model.ctr)**2) + 1.0*ew_crit_s2(ew, ew_l)\n",
                "                loss.backward(); opt.step()\n",
                "            model.upd(cls.detach()); tl += loss.item()\n",
                "        avg = tl/len(s2_loader); print(f\"  {ep+1}: {avg:.4f}\")\n",
                "        if avg < best_s2: best_s2 = avg; torch.save(model.state_dict(), f\"{EW_OUTPUT}/bgl_ew_prewarn.pt\")\n",
                "    print(f\"Stage 2 best: {best_s2:.4f}\")\n",
                "    model.load_state_dict(torch.load(f\"{EW_OUTPUT}/bgl_ew_prewarn.pt\", map_location=device))\n",
                "else:\n",
                "    print(\"No clean pre-warning windows! Skipping Stage 2.\")\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# STAGE 2: Pre-Warning Only Fine-tuning\nprint(\"\\n\" + \"=\"*60)\nprint(\"STAGE 2: Pre-Warning Only (clean windows)\")\nprint(\"=\"*60)\n\nif len(s2_prewarn) > 0:\n    model.load_state_dict(torch.load(f\"{EW_OUTPUT}/bgl_ew_best.pt\", map_location=device))\n    \n    s2_ds = BalancedDataset(s2_windows, VOCAB_SIZE, ratio=3)\n    s2_loader = DataLoader(s2_ds, batch_size=BATCH_SIZE, shuffle=True)\n    s2_pos_weight = (len(s2_windows) - s2_pos) / max(s2_pos, 1)\n    ew_crit_s2 = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([s2_pos_weight], device=device))\n    \n    opt = torch.optim.AdamW(model.parameters(), lr=5e-6)\n    best_s2 = float('inf')\n    \n    for ep in range(8):\n        model.train(); tl = 0\n        for b in tqdm(s2_loader, desc=f\"S2.{ep+1}\"):\n            ids, mask, ew_l, mlm_l = b['ids'].to(device), b['mask'].to(device), b['ew_label'].to(device), b['mlm_labels'].to(device)\n            opt.zero_grad()\n            if scaler:\n                with torch.amp.autocast('cuda'):\n                    mlm_lg, cls, ew = model(ids, mask)\n                    loss = 0.2*F.cross_entropy(mlm_lg.view(-1,VOCAB_SIZE), mlm_l.view(-1), ignore_index=-100) + 0.1*torch.mean((cls-model.ctr)**2) + ew_crit_s2(ew, ew_l)\n                scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n            else:\n                mlm_lg, cls, ew = model(ids, mask)\n                loss = 0.2*F.cross_entropy(mlm_lg.view(-1,VOCAB_SIZE), mlm_l.view(-1), ignore_index=-100) + 0.1*torch.mean((cls-model.ctr)**2) + ew_crit_s2(ew, ew_l)\n                loss.backward(); opt.step()\n            model.upd(cls.detach()); tl += loss.item()\n        avg = tl/len(s2_loader); print(f\"  {ep+1}: {avg:.4f}\")\n        if avg < best_s2:\n            best_s2 = avg\n            torch.save(model.state_dict(), f\"{EW_OUTPUT}/bgl_ew_prewarn.pt\")\n    print(f\"Stage 2 best: {best_s2:.4f}\")\n    model.load_state_dict(torch.load(f\"{EW_OUTPUT}/bgl_ew_prewarn.pt\", map_location=device))\nelse:\n    print(\"No pre-warning windows! Using Stage 1 model.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# EVALUATION (True Pre-Warning: score before first anomaly, val threshold)\nprint(\"\\nEVALUATION (True Pre-Warning)\")\nmodel.eval()\n\n@torch.no_grad()\ndef score_trace(tids, step=4):\n    probs = []\n    for k in range(min(WINDOW_SIZE, len(tids)), len(tids)+1, step):\n        s = [min(t, VOCAB_SIZE-1) for t in tids[max(0,k-WINDOW_SIZE):k]]\n        if len(s) < 5: continue\n        tok = [CLS]+s[:CONTEXT_LEN-2]+[SEP]+[PAD]*(CONTEXT_LEN-len(s[:CONTEXT_LEN-2])-2)\n        ids = torch.tensor([tok], device=device)\n        _, _, ew = model(ids)\n        probs.append((k, torch.sigmoid(ew).item()))\n    return probs\n\ndef first_anomaly_idx(trace):\n    events = trace.get('events', [])\n    for i, e in enumerate(events):\n        if e[2]: return i\n    return len(events)\n\n# Score all traces\nprint(\"Scoring test traces...\")\ntest_scores = []\nfor t in tqdm(test_failure):\n    probs = score_trace(t['tids'])\n    fa_idx = first_anomaly_idx(t)\n    # Max prob BEFORE first anomaly\n    pre_probs = [(k, p) for k, p in probs if k < fa_idx]\n    max_pre = max((p for _, p in pre_probs), default=0.0) if pre_probs else 0.0\n    test_scores.append({'trace': t, 'max_pre': max_pre, 'probs': probs, 'fa_idx': fa_idx, 'pre_probs': pre_probs})\n\nnormal_scores = []\nfor t in tqdm(test_normal):\n    probs = score_trace(t['tids'])\n    max_prob = max((p for _, p in probs), default=0.0)\n    normal_scores.append({'trace': t, 'max_prob': max_prob})\n\nprint(f\"Scored: {len(test_scores)} F, {len(normal_scores)} N\")\n\n# Threshold from validation (0.99 quantile of normal)\nval_normal_probs = [s['max_prob'] for s in normal_scores[:len(normal_scores)//2]]  # Use half as val\nthreshold = np.quantile(val_normal_probs, 0.99) if val_normal_probs else 0.5\nprint(f\"Threshold (0.99 quantile): {threshold:.4f}\")\n\n# Evaluate\ntp, fp, leads = 0, 0, []\nfor s in test_scores:\n    if s['max_pre'] > threshold:\n        tp += 1\n        # Lead = first alarm idx to first anomaly idx\n        alarm_idx = next((k for k, p in s['pre_probs'] if p > threshold), s['fa_idx'])\n        lead = s['fa_idx'] - alarm_idx\n        if lead > 0: leads.append(lead)\n\nfor s in normal_scores[len(normal_scores)//2:]:  # Test normals\n    if s['max_prob'] > threshold:\n        fp += 1\n\nnF = len(test_scores)\nnN = len(normal_scores) - len(normal_scores)//2\nrecall = tp / nF if nF > 0 else 0\nfar = fp / nN if nN > 0 else 0\nprecision = tp / (tp + fp) if (tp + fp) > 0 else 0\nf1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n\nprint(f\"\\n=== TRUE PRE-WARNING RESULTS ===\")\nprint(f\"Recall: {recall:.3f} ({tp}/{nF})\")\nprint(f\"FAR: {far:.3f} ({fp}/{nN})\")\nprint(f\"Precision: {precision:.3f}\")\nprint(f\"F1: {f1:.3f}\")\nif leads:\n    print(f\"Lead: median={np.median(leads):.0f}, mean={np.mean(leads):.1f} events\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# F1-OPTIMAL + METRICS (FIXED: lead to first anomaly)\n",
                "all_probs = [s['max_prob'] for s in failure_scores] + [s['max_prob'] for s in normal_scores]\n",
                "all_labels = [1]*len(failure_scores) + [0]*len(normal_scores)\n",
                "\n",
                "auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else 0.5\n",
                "prec, rec, thr = precision_recall_curve(all_labels, all_probs)\n",
                "f1 = 2*prec*rec/(prec+rec+1e-9)\n",
                "best_idx = f1.argmax()\n",
                "TH = thr[best_idx] if best_idx < len(thr) else thr[-1] if len(thr) > 0 else 0.5\n",
                "\n",
                "tp, leads = [], []\n",
                "for s in failure_scores:\n",
                "    if s['max_prob'] > TH:\n",
                "        tp.append(s)\n",
                "        # FIXED: Lead to FIRST ANOMALY, not trace end\n",
                "        events = s['trace'].get('events', [])\n",
                "        first_anom_idx = next((i for i, e in enumerate(events) if e[2]), len(events))\n",
                "        for k, p in s['probs']:\n",
                "            if p > TH:\n",
                "                lead = first_anom_idx - k\n",
                "                if lead > 0:\n",
                "                    leads.append(lead)\n",
                "                break\n",
                "fp = [s for s in normal_scores if s['max_prob'] > TH]\n",
                "\n",
                "recall = len(tp)/len(failure_scores) if failure_scores else 0\n",
                "far = len(fp)/len(normal_scores) if normal_scores else 0\n",
                "precision = len(tp)/(len(tp)+len(fp)) if (len(tp)+len(fp))>0 else 0\n",
                "f1_final = 2*precision*recall/(precision+recall) if (precision+recall)>0 else 0\n",
                "\n",
                "print(f\"\\n=== RESULTS ===\")\n",
                "print(f\"AUC: {auc:.4f}, TH: {TH:.4f}\")\n",
                "print(f\"F1: {f1_final:.4f}, P: {precision:.4f}, R: {recall:.4f}, FAR: {far:.4f}\")\n",
                "if leads: print(f\"Lead: median={np.median(leads):.0f}, mean={np.mean(leads):.0f} (to first anomaly)\")\n",
                "print(f\"TP: {len(tp)}, FP: {len(fp)}, FN: {len(failure_scores)-len(tp)}, TN: {len(normal_scores)-len(fp)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SAVE\n",
                "results = {'dataset': 'BGL', 'method': 'joint_ew_head_v2',\n",
                "    'metrics': {'auc': float(auc), 'threshold': float(TH), 'f1': float(f1_final),\n",
                "        'precision': float(precision), 'recall': float(recall), 'far': float(far),\n",
                "        'lead_median': float(np.median(leads)) if leads else 0,\n",
                "        'lead_mean': float(np.mean(leads)) if leads else 0}}\n",
                "with open(f\"{EW_OUTPUT}/bgl_ew_results.json\", 'w') as f: json.dump(results, f, indent=2)\n",
                "print(f\"Saved: {EW_OUTPUT}/bgl_ew_results.json\")\n",
                "print(json.dumps(results['metrics'], indent=2))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Post-Training Analysis: validation-calibrated thresholds, lead-to-first-anomaly, FAR\u2013Recall, PR/ROC, CIs\n",
                "import math, statistics\n",
                "from sklearn.metrics import auc, confusion_matrix\n",
                "\n",
                "# 1) Helpers --------------------------------------------------------------\n",
                "\n",
                "def first_anomaly_index(trace):\n",
                "    events = trace.get('events') or []\n",
                "    for i, (_, _, is_anom) in enumerate(events):\n",
                "        if is_anom:\n",
                "            return i\n",
                "    return None\n",
                "\n",
                "@torch.no_grad()\n",
                "def trace_scores_pre_anom(trace, step=8):\n",
                "    tids = trace['tids']\n",
                "    probs = score_trace(tids, step=step)\n",
                "    q = first_anomaly_index(trace)\n",
                "    if q is None:\n",
                "        max_pre = max((p for _, p in probs), default=0.0)\n",
                "    else:\n",
                "        max_pre = max((p for k, p in probs if (k - 1) < q), default=0.0)\n",
                "    return max_pre, probs, q\n",
                "\n",
                "\n",
                "def earliest_crossing_k(probs, threshold, first_idx):\n",
                "    for k, p in probs:\n",
                "        if p > threshold and (first_idx is None or (k - 1) < first_idx):\n",
                "            return k\n",
                "    return None\n",
                "\n",
                "\n",
                "def lead_events_from_crossing(k_cross, first_idx):\n",
                "    if k_cross is None or first_idx is None:\n",
                "        return None\n",
                "    return max(0, first_idx - k_cross + 1)\n",
                "\n",
                "\n",
                "def split_validation_test(norm_list, fail_list, val_ratio=0.3, seed=SEED):\n",
                "    rng = np.random.RandomState(seed)\n",
                "    nN, nF = len(norm_list), len(fail_list)\n",
                "    nN_val = int(max(1, round(nN * val_ratio))) if nN > 0 else 0\n",
                "    nF_val = int(max(1, round(nF * val_ratio))) if nF > 0 else 0\n",
                "    n_idx = rng.permutation(nN) if nN > 0 else np.array([], dtype=int)\n",
                "    f_idx = rng.permutation(nF) if nF > 0 else np.array([], dtype=int)\n",
                "    val_norm = [norm_list[i] for i in n_idx[:nN_val]]\n",
                "    tst_norm = [norm_list[i] for i in n_idx[nN_val:]]\n",
                "    val_fail = [fail_list[i] for i in f_idx[:nF_val]]\n",
                "    tst_fail = [fail_list[i] for i in f_idx[nF_val:]]\n",
                "    return val_norm, val_fail, tst_norm, tst_fail\n",
                "\n",
                "# 2) Build validation/test splits ----------------------------------------\n",
                "val_normal, val_failure, final_normal, final_failure = split_validation_test(\n",
                "    test_normal, test_failure, val_ratio=0.3, seed=SEED)\n",
                "print(f\"Validation: {len(val_normal)} N, {len(val_failure)} F | Test: {len(final_normal)} N, {len(final_failure)} F\")\n",
                "\n",
                "val_norm_scores = [trace_scores_pre_anom(t)[0] for t in tqdm(val_normal, desc=\"VAL normal scores\")]\n",
                "val_fail_scores = [trace_scores_pre_anom(t)[0] for t in tqdm(val_failure, desc=\"VAL failure scores\")]\n",
                "\n",
                "final_norm_sc = []\n",
                "final_fail_sc = []\n",
                "final_fail_meta = []\n",
                "for t in tqdm(final_normal, desc=\"TEST normal scores\"):\n",
                "    s, _, _ = trace_scores_pre_anom(t)\n",
                "    final_norm_sc.append(s)\n",
                "for t in tqdm(final_failure, desc=\"TEST failure scores\"):\n",
                "    s, pr, q = trace_scores_pre_anom(t)\n",
                "    final_fail_sc.append(s)\n",
                "    final_fail_meta.append((pr, q))\n",
                "\n",
                "# 3) Threshold by FAR on validation --------------------------------------\n",
                "far_targets = [0.001, 0.005, 0.01, 0.02, 0.05]\n",
                "\n",
                "def threshold_for_far(norm_scores, far):\n",
                "    if len(norm_scores) == 0:\n",
                "        return 1.0\n",
                "    q = max(0.0, min(1.0, 1.0 - far))\n",
                "    return float(np.quantile(norm_scores, q))\n",
                "\n",
                "calib = {float(ft): threshold_for_far(val_norm_scores, ft) for ft in far_targets}\n",
                "print(\"Calibrated thresholds (VAL):\", {k: round(v, 4) for k, v in calib.items()})\n",
                "\n",
                "# 4) Evaluate on TEST -----------------------------------------------------\n",
                "\n",
                "def evaluate_at_threshold(th):\n",
                "    tp = 0; fp = 0; leads = []\n",
                "    for (probs, q) in final_fail_meta:\n",
                "        kx = earliest_crossing_k(probs, th, q)\n",
                "        if kx is not None:\n",
                "            tp += 1\n",
                "            ld = lead_events_from_crossing(kx, q)\n",
                "            if ld is not None: leads.append(ld)\n",
                "    for s in final_norm_sc:\n",
                "        if s > th: fp += 1\n",
                "    nF = len(final_fail_meta) or 1\n",
                "    nN = len(final_norm_sc) or 1\n",
                "    recall = tp / nF\n",
                "    far = fp / nN\n",
                "    precision = tp / max(tp + fp, 1)\n",
                "    f1 = 2 * precision * recall / max(precision + recall, 1e-9)\n",
                "    lead_stats = {\n",
                "        'median': float(np.median(leads)) if leads else 0.0,\n",
                "        'mean': float(np.mean(leads)) if leads else 0.0,\n",
                "        'p25': float(np.percentile(leads, 25)) if leads else 0.0,\n",
                "        'p75': float(np.percentile(leads, 75)) if leads else 0.0,\n",
                "        'count': len(leads)\n",
                "    }\n",
                "    return {'f1': float(f1), 'precision': float(precision), 'recall': float(recall),\n",
                "            'far': float(far), 'lead': lead_stats,\n",
                "            'tp': int(tp), 'fp': int(fp), 'nF': int(nF), 'nN': int(nN)}\n",
                "\n",
                "far_curve = []\n",
                "for ft in far_targets:\n",
                "    th = calib[float(ft)]\n",
                "    m = evaluate_at_threshold(th)\n",
                "    far_curve.append({'far_target': float(ft), 'threshold': th, **m})\n",
                "\n",
                "op_target = 0.01 if 0.01 in far_targets else far_targets[min(2, len(far_targets)-1)]\n",
                "op_th = calib[float(op_target)]\n",
                "op_metrics = evaluate_at_threshold(op_th)\n",
                "\n",
                "# 5) PR/ROC on TEST -------------------------------------------------------\n",
                "all_scores = np.array(final_fail_sc + final_norm_sc, dtype=float)\n",
                "all_labels = np.array([1]*len(final_fail_sc) + [0]*len(final_norm_sc), dtype=int)\n",
                "roc = float(roc_auc_score(all_labels, all_scores)) if len(set(all_labels))>1 else 0.5\n",
                "pr_p, pr_r, _ = precision_recall_curve(all_labels, all_scores)\n",
                "pr = float(auc(pr_r, pr_p)) if len(pr_r)>1 else 0.0\n",
                "\n",
                "# 6) Bootstrap 95% CI -----------------------------------------------------\n",
                "\n",
                "def bootstrap_ci(n_boot=300, seed=SEED):\n",
                "    rng = np.random.RandomState(seed)\n",
                "    f_idx = np.arange(len(final_fail_meta))\n",
                "    n_idx = np.arange(len(final_norm_sc))\n",
                "    f1s, recs, fars = [], [], []\n",
                "    for _ in range(n_boot):\n",
                "        bf = rng.choice(f_idx, size=len(f_idx), replace=True) if len(f_idx)>0 else []\n",
                "        bn = rng.choice(n_idx, size=len(n_idx), replace=True) if len(n_idx)>0 else []\n",
                "        tp = 0; fp = 0\n",
                "        for i in bf:\n",
                "            probs, q = final_fail_meta[i]\n",
                "            if earliest_crossing_k(probs, op_th, q) is not None:\n",
                "                tp += 1\n",
                "        for j in bn:\n",
                "            if final_norm_sc[j] > op_th:\n",
                "                fp += 1\n",
                "        nF = max(1, len(f_idx)); nN = max(1, len(n_idx))\n",
                "        recall = tp / nF\n",
                "        far = fp / nN\n",
                "        precision = tp / max(tp + fp, 1)\n",
                "        f1 = 2*precision*recall / max(precision+recall, 1e-9)\n",
                "        f1s.append(f1); recs.append(recall); fars.append(far)\n",
                "    def ci(arr):\n",
                "        if not arr: return [0.0, 0.0]\n",
                "        lo, hi = np.percentile(arr, [2.5, 97.5])\n",
                "        return [float(lo), float(hi)]\n",
                "    return {'f1': ci(f1s), 'recall': ci(recs), 'far': ci(fars)}\n",
                "\n",
                "cis = bootstrap_ci()\n",
                "\n",
                "# 7) Save consolidated JSON -----------------------------------------------\n",
                "report = {\n",
                "    'dataset': 'BGL',\n",
                "    'method': 'true_prewarn_analysis',\n",
                "    'config': {\n",
                "        'delta_min': int(DELTA_MIN),\n",
                "        'window_size': int(WINDOW_SIZE),\n",
                "        'step_size': 32,\n",
                "        'far_targets': far_targets\n",
                "    },\n",
                "    'validation': {\n",
                "        'n_normal': len(val_normal), 'n_failure': len(val_failure),\n",
                "        'thresholds_by_far': {str(k): float(v) for k, v in calib.items()}\n",
                "    },\n",
                "    'test': {\n",
                "        'n_normal': len(final_normal), 'n_failure': len(final_failure),\n",
                "        'operating_point': {'far_target': float(op_target), 'threshold': float(op_th)},\n",
                "        'metrics': {\n",
                "            'roc_auc': roc,\n",
                "            'pr_auc': pr,\n",
                "            **op_metrics\n",
                "        },\n",
                "        'ci_95': cis\n",
                "    },\n",
                "    'far_recall_curve': far_curve,\n",
                "    'notes': 'Threshold calibrated on validation normals by per-trace FAR; lead measured to FIRST anomaly event.'\n",
                "}\n",
                "\n",
                "with open(os.path.join(EW_OUTPUT, 'bgl_ew_analysis.json'), 'w') as f:\n",
                "    json.dump(report, f, indent=2)\n",
                "print(f\"\\n\u2713 Saved analysis to {EW_OUTPUT}/bgl_ew_analysis.json\")\n",
                "print(json.dumps(report['test']['metrics'], indent=2))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}