{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Prefix Scoring with Per-Trace FPR Calibration\n",
                "\n",
                "**Outputs:** FAR-Recall curve, Timeline plot, Lead distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#=============================================================================\n",
                "# SETUP\n",
                "#=============================================================================\n",
                "import os, json, random\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from tqdm import tqdm\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")\n",
                "\n",
                "BASE = \"/teamspace/studios/this_studio\"\n",
                "V1_PATH = f\"{BASE}/content/LogHub_HDFS/HDFS_v1/preprocessed/Event_traces.csv\"\n",
                "CKPT_DIR = f\"{BASE}/checkpoints\"\n",
                "OUTPUT_DIR = f\"{BASE}/output-prefix\"\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "CONTEXT_LEN, D_MODEL, N_HEADS, N_LAYERS = 128, 256, 8, 4\n",
                "PAD, CLS, MASK, SEP, OFF = 0, 1, 2, 3, 4\n",
                "SEED = 42\n",
                "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#=============================================================================\n",
                "# LOAD DATA & MODEL\n",
                "#=============================================================================\n",
                "df = pd.read_csv(V1_PATH)\n",
                "v1_normal, v1_failure = [], []\n",
                "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"V1\"):\n",
                "    features = str(row.get('Features', '[]')).strip('[]\"')\n",
                "    events = [int(e.strip().strip(\"'\")[1:]) for e in features.split(',') if e.strip().startswith('E')]\n",
                "    if events:\n",
                "        (v1_normal if row['Label'] == 'Success' else v1_failure).append(events)\n",
                "\n",
                "def seed_split(seqs, r=0.2):\n",
                "    rng = np.random.RandomState(SEED)\n",
                "    idx = rng.permutation(len(seqs))\n",
                "    s = int(len(seqs)*(1-r))\n",
                "    return [seqs[i] for i in idx[:s]], [seqs[i] for i in idx[s:]]\n",
                "\n",
                "normal_val, normal_test = seed_split(v1_normal)\n",
                "failure_val, failure_test = seed_split(v1_failure)\n",
                "print(f\"Normal: {len(v1_normal):,}, Failure: {len(v1_failure):,}\")\n",
                "print(f\"VAL: {len(normal_val)} N | TEST: {len(normal_test)} N, {len(failure_test)} F\")\n",
                "\n",
                "class LogBERT(nn.Module):\n",
                "    def __init__(self, vs, dm=D_MODEL, nh=N_HEADS, nl=N_LAYERS, ml=CONTEXT_LEN):\n",
                "        super().__init__()\n",
                "        self.tok = nn.Embedding(vs, dm, padding_idx=PAD)\n",
                "        self.pos = nn.Embedding(ml, dm)\n",
                "        self.drop = nn.Dropout(0.1)\n",
                "        el = nn.TransformerEncoderLayer(dm, nh, dm*4, 0.1, 'gelu', batch_first=True)\n",
                "        self.enc = nn.TransformerEncoder(el, nl)\n",
                "        self.head = nn.Linear(dm, vs)\n",
                "        self.register_buffer('ctr', torch.zeros(dm))\n",
                "    def forward(self, ids, mask=None):\n",
                "        x = self.tok(ids) + self.pos(torch.arange(ids.size(1), device=ids.device))\n",
                "        h = self.enc(self.drop(x), src_key_padding_mask=(mask==0) if mask is not None else None)\n",
                "        return self.head(h), h[:,0,:]\n",
                "\n",
                "ckpt = torch.load(f\"{CKPT_DIR}/logbert_ep11.pt\", map_location=device)\n",
                "VOCAB_SIZE = ckpt['model_state_dict']['tok.weight'].shape[0]\n",
                "model = LogBERT(VOCAB_SIZE).to(device)\n",
                "model.load_state_dict(ckpt['model_state_dict'])\n",
                "model.ctr = ckpt['center'].to(device)\n",
                "model.eval()\n",
                "print(f\"✅ Model: vocab={VOCAB_SIZE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#=============================================================================\n",
                "# SCORING + LENGTH NORMALIZATION\n",
                "#=============================================================================\n",
                "@torch.no_grad()\n",
                "def score_prefix(seq, plen):\n",
                "    s = [min(t+OFF, VOCAB_SIZE-1) for t in seq[:plen][:CONTEXT_LEN-2]]\n",
                "    tok = [CLS] + s + [SEP] + [PAD]*(CONTEXT_LEN-len(s)-2)\n",
                "    ids = torch.tensor([tok], device=device)\n",
                "    _, cls = model(ids)\n",
                "    return torch.sum((cls - model.ctr)**2).item()\n",
                "\n",
                "PREFIX_LENGTHS = list(range(10, CONTEXT_LEN+1, 10))\n",
                "normal_sample = normal_val[:2000]\n",
                "\n",
                "mu_k, sigma_k = {}, {}\n",
                "for k in tqdm(PREFIX_LENGTHS, desc=\"μ,σ\"):\n",
                "    scores = [score_prefix(seq, k) for seq in normal_sample if len(seq) >= k]\n",
                "    mu_k[k] = np.mean(scores) if scores else 0\n",
                "    sigma_k[k] = np.std(scores) + 1e-6 if scores else 1\n",
                "\n",
                "def z_score(s, k):\n",
                "    return (s - mu_k.get(k, 0)) / sigma_k.get(k, 1)\n",
                "\n",
                "def trace_score(seq, step=10):\n",
                "    max_k = min(len(seq), CONTEXT_LEN)\n",
                "    z_scores = [z_score(score_prefix(seq, k), k) for k in range(10, max_k+1, step)]\n",
                "    return max(z_scores) if z_scores else 0\n",
                "\n",
                "print(\"Computing trace_scores...\")\n",
                "normal_trace_scores = np.array([trace_score(seq) for seq in tqdm(normal_sample, desc=\"Normal\")])\n",
                "failure_trace_scores = np.array([trace_score(seq) for seq in tqdm(failure_test, desc=\"Failure\")])\n",
                "print(f\"Normal: mean={normal_trace_scores.mean():.4f}, Failure: mean={failure_trace_scores.mean():.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#=============================================================================\n",
                "# FAR-RECALL CURVE (Key visualization)\n",
                "#=============================================================================\n",
                "FAR_VALUES = [0.001, 0.005, 0.01, 0.02, 0.05, 0.10]  # 0.1% to 10%\n",
                "\n",
                "far_recall_data = []\n",
                "for far in FAR_VALUES:\n",
                "    th = np.quantile(normal_trace_scores, 1 - far)\n",
                "    recall = (failure_trace_scores > th).mean()\n",
                "    far_recall_data.append({'far': far, 'threshold': th, 'recall': recall})\n",
                "    print(f\"FAR={far*100:5.1f}% → TH={th:.3f} → Recall={recall:.1%}\")\n",
                "\n",
                "# Plot\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "fars = [d['far']*100 for d in far_recall_data]\n",
                "recalls = [d['recall']*100 for d in far_recall_data]\n",
                "\n",
                "ax.plot(fars, recalls, 'o-', color='steelblue', linewidth=2, markersize=10)\n",
                "\n",
                "# Annotate points\n",
                "for i, d in enumerate(far_recall_data):\n",
                "    ax.annotate(f\"{d['recall']*100:.0f}%\", (fars[i], recalls[i]), \n",
                "                textcoords=\"offset points\", xytext=(5, 10), fontsize=10)\n",
                "\n",
                "# Highlight operating point (FAR=1%)\n",
                "ax.axvline(x=1, color='red', linestyle='--', alpha=0.5, label='Operating point (FAR=1%)')\n",
                "\n",
                "ax.set_xlabel('False Alarm Rate (%)', fontsize=12)\n",
                "ax.set_ylabel('Recall (%)', fontsize=12)\n",
                "ax.set_title('FAR–Recall Trade-off (Prefix Scoring)', fontsize=14, fontweight='bold')\n",
                "ax.set_xscale('log')\n",
                "ax.set_xticks([0.1, 0.5, 1, 2, 5, 10])\n",
                "ax.get_xaxis().set_major_formatter(plt.ScalarFormatter())\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{OUTPUT_DIR}/far_recall_curve.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "print(f\"✅ Saved: {OUTPUT_DIR}/far_recall_curve.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#=============================================================================\n",
                "# EARLY WARNING AT OPERATING POINT (FAR=1%)\n",
                "#=============================================================================\n",
                "FAR_TARGET = 0.01\n",
                "TH = np.quantile(normal_trace_scores, 1 - FAR_TARGET)\n",
                "print(f\"Operating point: FAR={FAR_TARGET*100}%, TH={TH:.4f}\")\n",
                "\n",
                "def early_detect(seq, th, step=5):\n",
                "    max_k = min(len(seq), CONTEXT_LEN)\n",
                "    for k in range(10, max_k+1, step):\n",
                "        if z_score(score_prefix(seq, k), k) > th:\n",
                "            return k, len(seq)\n",
                "    return None, len(seq)\n",
                "\n",
                "print(f\"\\nEarly warning on TEST failures ({len(failure_test)})...\")\n",
                "ew_results = []\n",
                "for seq in tqdm(failure_test):\n",
                "    alarm, total = early_detect(seq, TH)\n",
                "    ew_results.append({'alarm': alarm, 'total': total, 'lead': (total-alarm) if alarm else 0, 'seq': seq})\n",
                "\n",
                "detected = [r for r in ew_results if r['alarm']]\n",
                "recall = len(detected) / len(ew_results)\n",
                "leads = [r['lead'] for r in detected]\n",
                "\n",
                "print(f\"\\n=== EARLY WARNING @ FAR={FAR_TARGET*100}% ===\")\n",
                "print(f\"Recall: {len(detected)}/{len(ew_results)} ({recall:.1%})\")\n",
                "if leads:\n",
                "    print(f\"Lead: median={np.median(leads):.0f}, mean={np.mean(leads):.0f}\")\n",
                "    print(f\"      p25={np.percentile(leads,25):.0f}, p75={np.percentile(leads,75):.0f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#=============================================================================\n",
                "# TIMELINE PLOT\n",
                "#=============================================================================\n",
                "def get_all_z_scores(seq, step=5):\n",
                "    max_k = min(len(seq), CONTEXT_LEN)\n",
                "    return [(k, z_score(score_prefix(seq, k), k)) for k in range(10, max_k+1, step)]\n",
                "\n",
                "sample_traces = []\n",
                "for r in detected[:2]:\n",
                "    sample_traces.append(('Failure (detected)', r['seq'], r['alarm']))\n",
                "for r in [r for r in ew_results if not r['alarm']][:1]:\n",
                "    sample_traces.append(('Failure (missed)', r['seq'], None))\n",
                "sample_traces.append(('Normal', normal_test[0], None))\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "for i, (label, seq, alarm_pos) in enumerate(sample_traces):\n",
                "    ax = axes[i//2, i%2]\n",
                "    zs = get_all_z_scores(seq, step=3)\n",
                "    x, y = [z[0] for z in zs], [z[1] for z in zs]\n",
                "    color = 'red' if 'Failure' in label else 'blue'\n",
                "    ax.plot(x, y, color=color, linewidth=2)\n",
                "    ax.axhline(y=TH, color='green', linestyle='--', linewidth=2, label=f'TH={TH:.2f}')\n",
                "    if alarm_pos:\n",
                "        ax.axvline(x=alarm_pos, color='orange', linestyle=':', linewidth=2, label=f'Alarm@{alarm_pos}')\n",
                "    ax.set_title(f'{label} (len={len(seq)})', fontsize=12, fontweight='bold')\n",
                "    ax.set_xlabel('Prefix length'); ax.set_ylabel('Z-score')\n",
                "    ax.legend(loc='upper left'); ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{OUTPUT_DIR}/timeline_plot.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "print(f\"✅ Saved: {OUTPUT_DIR}/timeline_plot.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#=============================================================================\n",
                "# LEAD DISTRIBUTION\n",
                "#=============================================================================\n",
                "if leads:\n",
                "    fig, ax = plt.subplots(figsize=(10, 5))\n",
                "    ax.hist(leads, bins=30, color='steelblue', edgecolor='white', alpha=0.8)\n",
                "    ax.axvline(x=np.median(leads), color='red', linestyle='--', lw=2, label=f'Median={np.median(leads):.0f}')\n",
                "    ax.axvline(x=np.mean(leads), color='orange', linestyle='--', lw=2, label=f'Mean={np.mean(leads):.0f}')\n",
                "    ax.set_xlabel('Lead events'); ax.set_ylabel('Count')\n",
                "    ax.set_title('Lead-Time Distribution', fontsize=14, fontweight='bold')\n",
                "    ax.legend(); ax.grid(True, alpha=0.3)\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(f'{OUTPUT_DIR}/lead_distribution.png', dpi=150)\n",
                "    plt.show()\n",
                "    print(f\"✅ Saved: {OUTPUT_DIR}/lead_distribution.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#=============================================================================\n",
                "# SAVE RESULTS\n",
                "#=============================================================================\n",
                "fp = sum(1 for seq in tqdm(normal_test[:500], desc=\"FP\") if early_detect(seq, TH)[0])\n",
                "\n",
                "results = {\n",
                "    'method': 'per_trace_far_calibration',\n",
                "    'operating_point': {'far_target': FAR_TARGET, 'threshold': float(TH)},\n",
                "    'far_recall_curve': far_recall_data,\n",
                "    'early_warning': {\n",
                "        'tested': len(ew_results), 'detected': len(detected), 'recall': float(recall),\n",
                "        'lead_events': {\n",
                "            'mean': float(np.mean(leads)) if leads else 0,\n",
                "            'median': float(np.median(leads)) if leads else 0,\n",
                "            'p25': float(np.percentile(leads, 25)) if leads else 0,\n",
                "            'p75': float(np.percentile(leads, 75)) if leads else 0\n",
                "        }\n",
                "    },\n",
                "    'false_positive': {'tested': 500, 'fp_count': fp, 'fp_rate': float(fp/500)}\n",
                "}\n",
                "\n",
                "with open(f'{OUTPUT_DIR}/early_warning.json', 'w') as f:\n",
                "    json.dump(results, f, indent=2)\n",
                "\n",
                "print('\\n' + '='*60)\n",
                "print('FINAL RESULTS')\n",
                "print('='*60)\n",
                "print(f\"FAR-Recall curve: {len(far_recall_data)} points\")\n",
                "print(f\"Recall @ FAR={FAR_TARGET*100}%: {recall:.1%}\")\n",
                "print(f\"Lead: median={np.median(leads):.0f}, mean={np.mean(leads):.0f}\")\n",
                "print(f\"FP: {fp}/500 ({fp/500:.1%})\")\n",
                "print(f\"\\n✅ Saved: {OUTPUT_DIR}/early_warning.json\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
