{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸš€ Full HDFS Dataset Training\n",
                "\n",
                "**Data:** LogHub_HDFS/HDFS_v1/preprocessed/Event_traces.csv (125MB)\n",
                "\n",
                "**Config:** Same as before, just more data\n",
                "\n",
                "**Output:** `output/`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install seaborn -q\n",
                "!mkdir -p output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, math, random, time, json, gc\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torch.cuda.amp import autocast, GradScaler\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"ðŸ–¥ï¸ Device: {device}\")\n",
                "if device == 'cuda':\n",
                "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
                "\n",
                "# Configuration\n",
                "SEEDS = [42, 123, 456]  # 3 seeds for speed\n",
                "CONTEXT_LEN = 128\n",
                "EPOCHS = 10\n",
                "BATCH_SIZE = 256  # Larger batch for more data\n",
                "LAMBDA_VHM = 0.2\n",
                "LR = 1e-4\n",
                "MASK_RATIO = 0.15\n",
                "USE_AMP = True\n",
                "OUTPUT_DIR = 'output'\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load FULL HDFS dataset\n",
                "# Try multiple paths\n",
                "PATHS = [\n",
                "    'content/Event_traces.csv',  # Lightning AI\n",
                "    '/content/Event_traces.csv',  # Colab\n",
                "    'Event_traces.csv'\n",
                "]\n",
                "\n",
                "HDFS_PATH = None\n",
                "for p in PATHS:\n",
                "    if os.path.exists(p):\n",
                "        HDFS_PATH = p\n",
                "        break\n",
                "\n",
                "if not HDFS_PATH:\n",
                "    raise FileNotFoundError(\"Upload Event_traces.csv (125MB) to content/\")\n",
                "\n",
                "print(f\"ðŸ“ Loading: {HDFS_PATH}\")\n",
                "df = pd.read_csv(HDFS_PATH)\n",
                "print(f\"ðŸ“Š Total rows: {len(df):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Parse sessions\n",
                "raw, labels = [], []\n",
                "for _, r in df.iterrows():\n",
                "    f = str(r['Features']).strip('[]')\n",
                "    s = [e.strip().strip(\"'\") for e in f.split(',') if e.strip()]\n",
                "    if len(s) >= 2:\n",
                "        raw.append(s)\n",
                "        labels.append(0 if 'success' in str(r['Label']).lower() else 1)\n",
                "\n",
                "labels = np.array(labels)\n",
                "print(f\"ðŸ“Š Valid sessions: {len(raw):,}\")\n",
                "print(f\"   Anomalies: {labels.sum():,} ({labels.mean()*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build vocab\n",
                "e2i = {'[PAD]': 0, '[UNK]': 1, '[CLS]': 2, '[MASK]': 3}\n",
                "for i, e in enumerate(sorted(set(e for s in raw for e in s))):\n",
                "    e2i[e] = i + 4\n",
                "V = len(e2i)\n",
                "print(f\"ðŸ“ Vocab size: {V}\")\n",
                "\n",
                "def encode(seq):\n",
                "    enc = [e2i.get(e, 1) for e in seq][:CONTEXT_LEN]\n",
                "    return enc + [0] * (CONTEXT_LEN - len(enc))\n",
                "\n",
                "print(\"Encoding...\")\n",
                "X = np.array([encode(s) for s in raw])\n",
                "print(f\"   Shape: {X.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split\n",
                "np.random.seed(0)\n",
                "idx = np.random.permutation(len(X))\n",
                "train_end = int(len(X) * 0.7)\n",
                "test_idx = idx[int(len(X) * 0.85):]\n",
                "train_idx = idx[:train_end]\n",
                "train_idx = train_idx[labels[train_idx] == 0]  # Normal only\n",
                "\n",
                "X_train, X_test = X[train_idx], X[test_idx]\n",
                "y_test = labels[test_idx]\n",
                "\n",
                "print(f\"ðŸ“Š Split:\")\n",
                "print(f\"   Train (normal): {len(X_train):,}\")\n",
                "print(f\"   Test: {len(X_test):,} (anomaly: {y_test.sum():,})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MaskedLMDataset(Dataset):\n",
                "    def __init__(self, X, V, mask_ratio=0.15):\n",
                "        self.X, self.V, self.mask_ratio = X, V, mask_ratio\n",
                "    def __len__(self): return len(self.X)\n",
                "    def __getitem__(self, i):\n",
                "        orig = np.clip(self.X[i].copy(), 0, self.V-1)\n",
                "        masked, labels = orig.copy(), np.full_like(orig, -100)\n",
                "        nz = np.where(orig != 0)[0]\n",
                "        n_mask = max(1, int(len(nz) * self.mask_ratio))\n",
                "        if len(nz) > 0:\n",
                "            for p in np.random.choice(nz, min(n_mask, len(nz)), replace=False):\n",
                "                labels[p], masked[p] = orig[p], 3\n",
                "        return torch.LongTensor(masked), torch.LongTensor(orig), torch.LongTensor(labels)\n",
                "\n",
                "class PositionalEncoding(nn.Module):\n",
                "    def __init__(self, d, max_len=512):\n",
                "        super().__init__()\n",
                "        pe = torch.zeros(max_len, d)\n",
                "        pos = torch.arange(max_len).unsqueeze(1).float()\n",
                "        div = torch.exp(torch.arange(0, d, 2).float() * (-math.log(10000) / d))\n",
                "        pe[:, 0::2], pe[:, 1::2] = torch.sin(pos * div), torch.cos(pos * div)\n",
                "        self.register_buffer('pe', pe.unsqueeze(0))\n",
                "    def forward(self, x): return x + self.pe[:, :x.size(1)]\n",
                "\n",
                "class LogBERTVHM(nn.Module):\n",
                "    def __init__(self, V, d=128, h=4, L=4):\n",
                "        super().__init__()\n",
                "        self.d, self.V = d, V\n",
                "        self.emb = nn.Embedding(V, d, padding_idx=0)\n",
                "        self.pos = PositionalEncoding(d)\n",
                "        self.tf = nn.TransformerEncoder(nn.TransformerEncoderLayer(d, h, d*4, 0.1, batch_first=True), L)\n",
                "        self.fc = nn.Linear(d, V)\n",
                "        self.register_buffer('center', torch.zeros(d))\n",
                "    def forward(self, x):\n",
                "        x = torch.clamp(x, 0, self.V-1)\n",
                "        return self.fc(self.tf(self.pos(self.emb(x) * math.sqrt(self.d)), src_key_padding_mask=(x==0)))\n",
                "    def get_emb(self, x):\n",
                "        x = torch.clamp(x, 0, self.V-1)\n",
                "        m = (~(x==0)).unsqueeze(-1).float()\n",
                "        return (self.tf(self.pos(self.emb(x) * math.sqrt(self.d)), src_key_padding_mask=(x==0)) * m).sum(1) / m.sum(1).clamp(min=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_model(seed):\n",
                "    t0 = time.time()\n",
                "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
                "    \n",
                "    dl = DataLoader(MaskedLMDataset(X_train, V, MASK_RATIO), BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
                "    model = LogBERTVHM(V).to(device)\n",
                "    opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
                "    crit = nn.CrossEntropyLoss(ignore_index=-100)\n",
                "    scaler = GradScaler() if USE_AMP else None\n",
                "    \n",
                "    # Init center (sample for speed)\n",
                "    model.eval()\n",
                "    with torch.no_grad():\n",
                "        sample_dl = DataLoader(MaskedLMDataset(X_train[:5000], V), 256)\n",
                "        model.center = torch.cat([model.get_emb(o.to(device)) for _, o, _ in sample_dl]).mean(0)\n",
                "    \n",
                "    model.train()\n",
                "    for ep in range(EPOCHS):\n",
                "        loss_sum, n_batch = 0, 0\n",
                "        for m, o, l in dl:\n",
                "            m, o, l = m.to(device), o.to(device), l.to(device)\n",
                "            opt.zero_grad()\n",
                "            if USE_AMP:\n",
                "                with autocast():\n",
                "                    lo = model(m)\n",
                "                    loss = crit(lo.view(-1, V), l.view(-1)) + LAMBDA_VHM * ((model.get_emb(o) - model.center)**2).sum(1).mean()\n",
                "                scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
                "            else:\n",
                "                lo = model(m)\n",
                "                loss = crit(lo.view(-1, V), l.view(-1)) + LAMBDA_VHM * ((model.get_emb(o) - model.center)**2).sum(1).mean()\n",
                "                loss.backward(); opt.step()\n",
                "            with torch.no_grad(): model.center = 0.99 * model.center + 0.01 * model.get_emb(o).mean(0)\n",
                "            loss_sum += loss.item(); n_batch += 1\n",
                "        print(f\"  Epoch {ep+1}/{EPOCHS}: Loss={loss_sum/n_batch:.4f}\")\n",
                "    return model, (time.time() - t0) / 60\n",
                "\n",
                "def score_sequences(model, X_data, n_samples=5):\n",
                "    model.eval()\n",
                "    scores = []\n",
                "    for seq in X_data:\n",
                "        seq = np.clip(seq, 0, V-1)\n",
                "        nz = seq[seq != 0]\n",
                "        if len(nz) < 2: scores.append(0); continue\n",
                "        pos = np.random.choice(len(nz), min(n_samples, len(nz)), replace=False)\n",
                "        mlm = 0\n",
                "        with torch.no_grad():\n",
                "            for p in pos:\n",
                "                m = nz.copy(); tok = m[p]; m[p] = 3\n",
                "                inp = np.zeros(CONTEXT_LEN, dtype=np.int64); inp[:len(m)] = m\n",
                "                lo = model(torch.LongTensor(inp).unsqueeze(0).to(device))\n",
                "                mlm += -math.log(F.softmax(lo[0, p].float(), -1)[tok].item() + 1e-10)\n",
                "            mlm /= len(pos)\n",
                "            inp = np.zeros(CONTEXT_LEN, dtype=np.int64); inp[:len(nz)] = nz\n",
                "            emb = model.get_emb(torch.LongTensor(inp).unsqueeze(0).to(device))\n",
                "            vhm = ((emb - model.center)**2).sum().item()\n",
                "        scores.append(mlm + 0.1 * vhm)\n",
                "    return np.array(scores)\n",
                "\n",
                "def eval_f1(sc, y):\n",
                "    best = {'F1': 0, 'P': 0, 'R': 0, 'th': 0}\n",
                "    for pct in range(30, 100):\n",
                "        th = np.percentile(sc, pct)\n",
                "        pr = (sc > th).astype(int)\n",
                "        tp, fp, fn = ((pr==1)&(y==1)).sum(), ((pr==1)&(y==0)).sum(), ((pr==0)&(y==1)).sum()\n",
                "        P, R = tp/(tp+fp+1e-10), tp/(tp+fn+1e-10)\n",
                "        F1 = 2*P*R/(P+R+1e-10)\n",
                "        if F1 > best['F1']: best = {'F1': F1, 'P': P, 'R': R, 'th': th}\n",
                "    return best"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train\n",
                "all_scores, all_results = [], []\n",
                "\n",
                "for i, seed in enumerate(SEEDS):\n",
                "    print(f\"\\n{'='*50}\\nðŸŒ± Seed {seed} ({i+1}/{len(SEEDS)})\\n{'='*50}\")\n",
                "    model, t = train_model(seed)\n",
                "    \n",
                "    print(\"  Scoring...\")\n",
                "    sc = score_sequences(model, X_test)\n",
                "    all_scores.append(sc)\n",
                "    \n",
                "    r = eval_f1(sc, y_test)\n",
                "    print(f\"  âœ… F1={r['F1']:.1%}, P={r['P']:.1%}, R={r['R']:.1%}, Time={t:.1f}min\")\n",
                "    all_results.append({'seed': seed, 'time': t, **r})\n",
                "    \n",
                "    np.save(f'{OUTPUT_DIR}/scores_seed_{seed}.npy', sc)\n",
                "    pd.DataFrame(all_results).to_csv(f'{OUTPUT_DIR}/results.csv', index=False)\n",
                "    del model; torch.cuda.empty_cache(); gc.collect()\n",
                "\n",
                "print(\"\\nâœ… Training Complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ensemble\n",
                "print(\"\\n\" + \"=\"*50 + \"\\nðŸŽ¯ ENSEMBLE RESULTS\\n\" + \"=\"*50)\n",
                "\n",
                "ens = np.mean(all_scores, axis=0)\n",
                "np.save(f'{OUTPUT_DIR}/scores_ensemble.npy', ens)\n",
                "\n",
                "r = eval_f1(ens, y_test)\n",
                "print(f\"\\nðŸ“Š Individual Avg F1: {np.mean([x['F1'] for x in all_results]):.1%}\")\n",
                "print(f\"ðŸ“Š Ensemble F1: {r['F1']:.1%}, P={r['P']:.1%}, R={r['R']:.1%}\")\n",
                "\n",
                "f1s = [x['F1'] for x in all_results]\n",
                "mean_f1, std_f1 = np.mean(f1s), np.std(f1s)\n",
                "print(f\"\\nðŸ“ˆ 95% CI: {mean_f1:.1%} Â± {1.96*std_f1/np.sqrt(len(f1s)):.1%}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save\n",
                "final = {\n",
                "    'dataset': 'HDFS_full',\n",
                "    'data_size': {'train': len(X_train), 'test': len(X_test)},\n",
                "    'config': {'seeds': SEEDS, 'epochs': EPOCHS, 'batch': BATCH_SIZE},\n",
                "    'individual': all_results,\n",
                "    'ensemble_f1': eval_f1(ens, y_test),\n",
                "    'comparison': {\n",
                "        'small_dataset_ensemble': 0.763,\n",
                "        'full_dataset_ensemble': r['F1']\n",
                "    }\n",
                "}\n",
                "with open(f'{OUTPUT_DIR}/final_results.json', 'w') as f:\n",
                "    json.dump(final, f, indent=2, default=float)\n",
                "\n",
                "print(f\"\\nâœ… Saved to {OUTPUT_DIR}/\")\n",
                "print(f\"\\nðŸ“Š COMPARISON:\")\n",
                "print(f\"   Small dataset (100k): 76.3% F1\")\n",
                "print(f\"   Full dataset ({len(X_train)+len(X_test):,}): {r['F1']:.1%} F1\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}